# Testes UnitÃ¡rios - Atende Ai

Este documento descreve a estrutura e execuÃ§Ã£o dos testes unitÃ¡rios do projeto Atende Ai.

## ğŸ“‹ VisÃ£o Geral

Os testes unitÃ¡rios foram criados para garantir a qualidade do cÃ³digo e prevenir regressÃµes antes de cada commit. Eles cobrem:

1. **Carregamento de dados no admin** - Testes para o painel administrativo
2. **Login no admin** - AutenticaÃ§Ã£o e autorizaÃ§Ã£o
3. **Webhook e resposta das mensagens do WhatsApp** - Processamento de mensagens
4. **IntegraÃ§Ã£o com APIs externas** - OpenAI, Twilio, Google Calendar, Google Sheets
5. **HistÃ³rico de mensagens** - Armazenamento e recuperaÃ§Ã£o de conversas

## ğŸ—ï¸ Estrutura dos Testes

```
backend/tests/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ conftest.py                    # ConfiguraÃ§Ã£o e fixtures
â”œâ”€â”€ test_admin_data_loading.py     # Testes de carregamento de dados
â”œâ”€â”€ test_admin_login.py            # Testes de login
â”œâ”€â”€ test_webhook_whatsapp.py       # Testes de webhook
â”œâ”€â”€ test_api_integrations.py       # Testes de integraÃ§Ã£o com APIs
â”œâ”€â”€ test_message_history.py         # Testes de histÃ³rico
â””â”€â”€ test_integration_full_flow.py  # Testes de integraÃ§Ã£o completa
```

## ğŸš€ Como Executar

### PrÃ©-requisitos

1. Instalar dependÃªncias de teste:
```bash
pip install -r requirements.txt
```

2. Configurar variÃ¡veis de ambiente para testes:
```bash
cp env.example .env.test
# Editar .env.test com configuraÃ§Ãµes de teste
```

### ExecuÃ§Ã£o BÃ¡sica

```bash
# Executar todos os testes
python run_tests.py all

# Executar testes especÃ­ficos
python run_tests.py admin
python run_tests.py webhook
python run_tests.py api
python run_tests.py history
python run_tests.py integration

# Executar com cobertura
python run_tests.py all --coverage

# Modo verboso
python run_tests.py all --verbose
```

### ExecuÃ§Ã£o com Pytest

```bash
# Todos os testes
pytest tests/

# Testes especÃ­ficos
pytest tests/test_admin_data_loading.py
pytest tests/test_webhook_whatsapp.py

# Com marcadores
pytest -m admin
pytest -m webhook
pytest -m "not slow"

# Com cobertura
pytest --cov=. --cov-report=html tests/
```

## ğŸ“Š Tipos de Teste

### 1. Testes de Carregamento de Dados (Admin)

**Arquivo:** `test_admin_data_loading.py`

Testa o carregamento de dados no painel administrativo:

- âœ… MÃ©tricas do admin
- âœ… Lista de empresas
- âœ… MÃ©tricas especÃ­ficas de empresa
- âœ… Lista de clientes
- âœ… Lista de usuÃ¡rios
- âœ… Logs do sistema
- âœ… Status do buffer
- âœ… Performance de carregamento

### 2. Testes de Login (Admin)

**Arquivo:** `test_admin_login.py`

Testa autenticaÃ§Ã£o e autorizaÃ§Ã£o:

- âœ… Login bem-sucedido
- âœ… Credenciais invÃ¡lidas
- âœ… UsuÃ¡rio inexistente
- âœ… ValidaÃ§Ã£o de token
- âœ… Controle de acesso (superuser vs usuÃ¡rio regular)
- âœ… Performance de login
- âœ… Logins simultÃ¢neos

### 3. Testes de Webhook (WhatsApp)

**Arquivo:** `test_webhook_whatsapp.py`

Testa processamento de mensagens do WhatsApp:

- âœ… Processamento de webhook
- âœ… Empresa inexistente
- âœ… Dados invÃ¡lidos
- âœ… Mensagens com mÃ­dia
- âœ… IntegraÃ§Ã£o com OpenAI
- âœ… Resposta via Twilio
- âœ… Tratamento de erros
- âœ… Armazenamento de mensagens
- âœ… Contexto de conversa
- âœ… LimitaÃ§Ã£o de taxa

### 4. Testes de IntegraÃ§Ã£o com APIs

**Arquivo:** `test_api_integrations.py`

Testa integraÃ§Ãµes com APIs externas:

- âœ… OpenAI (geraÃ§Ã£o de respostas)
- âœ… Twilio (envio de mensagens)
- âœ… Google Calendar (eventos)
- âœ… Google Sheets (leitura/escrita)
- âœ… Tratamento de erros
- âœ… Timeout e retry
- âœ… ValidaÃ§Ã£o de dados
- âœ… Performance

### 5. Testes de HistÃ³rico de Mensagens

**Arquivo:** `test_message_history.py`

Testa armazenamento e recuperaÃ§Ã£o de mensagens:

- âœ… Armazenamento de mensagens
- âœ… RecuperaÃ§Ã£o de histÃ³rico
- âœ… PaginaÃ§Ã£o
- âœ… Filtros por data
- âœ… OrdenaÃ§Ã£o por timestamp
- âœ… Mensagens do bot vs usuÃ¡rio
- âœ… Performance com muitas mensagens
- âœ… Acesso concorrente
- âœ… Integridade de dados

### 6. Testes de IntegraÃ§Ã£o Completa

**Arquivo:** `test_integration_full_flow.py`

Testa fluxos completos do sistema:

- âœ… Webhook â†’ Processamento â†’ Resposta
- âœ… Fluxo completo do admin
- âœ… Fluxo completo de conversa
- âœ… Tratamento de erros
- âœ… Performance
- âœ… SeguranÃ§a
- âœ… Integridade de dados
- âœ… OperaÃ§Ãµes concorrentes
- âœ… RecuperaÃ§Ã£o de erros
- âœ… Monitoramento

## ğŸ”§ ConfiguraÃ§Ã£o

### Fixtures (conftest.py)

O arquivo `conftest.py` contÃ©m fixtures comuns para todos os testes:

- `test_db_engine`: Banco de dados SQLite em memÃ³ria
- `test_db_session`: SessÃ£o do banco de dados
- `client`: Cliente de teste FastAPI
- `mock_redis`: Mock do Redis
- `mock_openai`: Mock do OpenAI
- `mock_twilio`: Mock do Twilio
- `mock_google_calendar`: Mock do Google Calendar
- `mock_google_sheets`: Mock do Google Sheets
- `sample_empresa`: Empresa de exemplo
- `sample_usuario`: UsuÃ¡rio de exemplo
- `sample_mensagem`: Mensagem de exemplo
- `auth_headers`: Headers de autenticaÃ§Ã£o

### Marcadores (Markers)

Os testes usam marcadores para categorizaÃ§Ã£o:

- `@pytest.mark.admin`: Testes do admin
- `@pytest.mark.webhook`: Testes de webhook
- `@pytest.mark.api`: Testes de API
- `@pytest.mark.history`: Testes de histÃ³rico
- `@pytest.mark.integration`: Testes de integraÃ§Ã£o
- `@pytest.mark.unit`: Testes unitÃ¡rios
- `@pytest.mark.slow`: Testes lentos

## ğŸ“ˆ Cobertura de CÃ³digo

Para gerar relatÃ³rio de cobertura:

```bash
# Instalar pytest-cov
pip install pytest-cov

# Executar com cobertura
pytest --cov=. --cov-report=html --cov-report=term-missing tests/

# Abrir relatÃ³rio
open htmlcov/index.html
```

## ğŸ› Debugging

### Executar teste especÃ­fico

```bash
# Teste especÃ­fico
pytest tests/test_admin_data_loading.py::TestAdminDataLoading::test_get_admin_metrics_success -v

# Com print statements
pytest tests/test_admin_data_loading.py::TestAdminDataLoading::test_get_admin_metrics_success -s
```

### Logs detalhados

```bash
# Com logs
pytest --log-cli-level=DEBUG tests/
```

## ğŸ”„ CI/CD

Para integraÃ§Ã£o com CI/CD, adicione ao pipeline:

```yaml
# Exemplo para GitHub Actions
- name: Run Tests
  run: |
    cd backend
    python run_tests.py all --coverage
    
- name: Upload Coverage
  uses: codecov/codecov-action@v3
  with:
    file: ./backend/coverage.xml
```

## ğŸ“ Boas PrÃ¡ticas

1. **Isolamento**: Cada teste deve ser independente
2. **Mocks**: Use mocks para APIs externas
3. **Fixtures**: Reutilize fixtures comuns
4. **Nomenclatura**: Nomes descritivos para testes
5. **DocumentaÃ§Ã£o**: Comente testes complexos
6. **Performance**: Testes devem ser rÃ¡pidos
7. **Cobertura**: Mantenha alta cobertura de cÃ³digo

## ğŸš¨ Troubleshooting

### Erro: "Module not found"
```bash
# Adicionar diretÃ³rio ao PYTHONPATH
export PYTHONPATH="${PYTHONPATH}:$(pwd)/backend"
```

### Erro: "Database connection failed"
```bash
# Verificar configuraÃ§Ã£o de banco de teste
# Os testes usam SQLite em memÃ³ria, nÃ£o precisam de banco externo
```

### Erro: "Mock not working"
```bash
# Verificar se o mock estÃ¡ no caminho correto
# Usar patch com caminho completo do mÃ³dulo
```

## ğŸ“ Suporte

Para dÃºvidas sobre os testes:

1. Verificar logs detalhados
2. Executar teste especÃ­fico com `-s`
3. Verificar fixtures em `conftest.py`
4. Consultar documentaÃ§Ã£o do pytest

---

**Lembre-se:** Execute os testes antes de cada commit para garantir a qualidade do cÃ³digo! ğŸš€ 