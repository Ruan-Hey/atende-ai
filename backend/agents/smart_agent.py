from typing import Dict, Any, List
try:
    from langchain_openai import ChatOpenAI
except ImportError:
    from langchain.chat_models import ChatOpenAI
try:
    from langchain.memory import ConversationBufferWindowMemory
except ImportError:
    from langchain_community.memory import ConversationBufferWindowMemory
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langchain_core.tools import tool as lc_tool
import logging
import json
import requests
from datetime import datetime

# Importar TrinksRules diretamente
from rules.trinks_rules import TrinksRules

logger = logging.getLogger(__name__)

class SmartAgent:
    """Agente inteligente que usa LLM para identificar inten√ß√µes e TrinksRules para executar fluxos"""
    
    def __init__(self, empresa_config: Dict[str, Any]):
        self.empresa_config = empresa_config
        
        # TrinksRules para opera√ß√µes espec√≠ficas da API Trinks
        self.trinks_rules = TrinksRules()
        
        # LLM para identifica√ß√£o inteligente de inten√ß√µes
        self.llm = ChatOpenAI(
            api_key=empresa_config.get('openai_key'),
            temperature=0.1,
            model="gpt-4o"
        )
        
        # Memory para contexto da conversa
        self.memory = ConversationBufferWindowMemory(
            k=20,
            return_messages=True
        )
        
        # Tools estruturadas
        self.tools = self._setup_tools()
        
        # Contexto da conversa atual
        self.current_conversation_state = None
        
        # Cache global de contextos por waid (WhatsApp ID)
        if not hasattr(SmartAgent, '_conversation_cache'):
            SmartAgent._conversation_cache = {}
    
    def _save_log_to_db(self, level: str, message: str, details: dict = None):
        """Salva log no banco de dados com empresa_id"""
        try:
            from main import save_log_to_db
            from database import SessionLocal
            
            empresa_id = self.empresa_config.get('empresa_id')
            if empresa_id:
                session = SessionLocal()
                try:
                    save_log_to_db(session, empresa_id, level, message, details)
                    
                    # üîî NOTIFICA√á√ÉO AUTOM√ÅTICA para erros cr√≠ticos
                    if level == 'ERROR':
                        self._send_error_notification(session, message, details, empresa_id)
                        
                finally:
                    session.close()
        except Exception as e:
            # Fallback para logging normal se falhar
            logger.error(f"Erro ao salvar log no banco: {e}")
            logger.error(message)
    
    def _send_error_notification(self, session, message: str, details: dict, empresa_id: int):
        """Envia notifica√ß√£o push para erros do agente - VERS√ÉO SIMPLIFICADA"""
        try:
            from notifications.webpush_service import WebPushService
            from notifications.models import NotificationRule
            
            # Buscar regra de notifica√ß√£o para erros do agente
            regra = session.query(NotificationRule).filter(
                NotificationRule.tipo == 'agente_error',
                NotificationRule.ativo == True
            ).first()
            
            if regra:
                # üÜï DADOS B√ÅSICOS - SEM CONSULTAS COMPLEXAS
                waid = details.get('waid')
                empresa_slug = self.empresa_config.get('slug', '')
                
                # üÜï ROTA SIMPLES - S√ì EMPRESA + WAID
                rota_conversa = f"/conversation/{empresa_slug}/{waid}" if waid else ""
                
                # Notifica√ß√£o b√°sica
                titulo = f"üö® Erro no Agente - {self.empresa_config.get('nome', 'Empresa')}"
                mensagem = f"Erro: {message[:100]}..."
                
                # Dados contexto simplificados
                dados_contexto = {
                    'empresa_id': empresa_id,
                    'empresa_slug': empresa_slug,
                    'rota_conversa': rota_conversa,
                    'waid': waid,
                    'tipo_erro': 'agente_error'
                }
                
                # Executar regra de notifica√ß√£o
                webpush_service = WebPushService()
                webpush_service.execute_notification_rule(
                    session, regra, titulo, mensagem, dados_contexto
                )
                
                logger.info(f"üîî Notifica√ß√£o de erro enviada para regra: {regra.nome}")
            else:
                logger.info("‚ÑπÔ∏è Nenhuma regra de notifica√ß√£o configurada para erros do agente")
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao enviar notifica√ß√£o: {e}")
    
    async def _force_trinks_error(self):
        """For√ßa erro no fluxo Trinks para teste"""
        try:
            # Simular erro no fluxo de agendamento sem service_id
            error_msg = "Erro no fluxo Trinks: service_id n√£o fornecido para agendamento"
            error_details = {
                'tool': 'trinks_booking',
                'error_type': 'missing_service_id',
                'user_message': 'Quero agendar um hor√°rio para amanh√£ √†s 14h'
            }
            
            # Salvar erro no banco (vai disparar notifica√ß√£o)
            from main import save_log_to_db
            from database import SessionLocal
            
            session = SessionLocal()
            try:
                save_log_to_db(session, self.empresa_config.get('empresa_id'), 'ERROR', error_msg, error_details)
                logger.info("üîî Erro Trinks for√ßado - notifica√ß√£o deveria ter sido enviada!")
            finally:
                session.close()
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao for√ßar erro Trinks: {e}")
    
    async def _force_agent_error(self):
        """For√ßa erro geral no agente para teste"""
        try:
            # Simular erro geral do agente
            error_msg = "Erro geral no agente: falha na execu√ß√£o da ferramenta"
            error_details = {
                'tool': 'general_execution',
                'error_type': 'tool_execution_failure',
                'context': 'test_forced_error'
            }
            
            # Salvar erro no banco (vai disparar notifica√ß√£o)
            from main import save_log_to_db
            from database import SessionLocal
            
            session = SessionLocal()
            try:
                save_log_to_db(session, self.empresa_config.get('empresa_id'), 'ERROR', error_msg, error_details)
                logger.info("üîî Erro do agente for√ßado - notifica√ß√£o deveria ter sido enviada!")
            finally:
                session.close()
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao for√ßar erro do agente: {e}")

    def _setup_tools(self) -> List:
        """Configura as tools dispon√≠veis usando as TrinksRules para executar opera√ß√µes"""
        tools = []
        
        @lc_tool("get_business_knowledge")
        def get_business_knowledge(key: str) -> str:
            """Consulta informa√ß√µes espec√≠ficas da empresa (hor√°rios, regras, promo√ß√µes, etc.)"""
            try:
                knowledge = self.empresa_config.get('knowledge_json', {})
                items = knowledge.get('items', [])
                
                key_lower = key.lower().strip()
                for item in items:
                    if isinstance(item, dict):
                        item_key = item.get('key', '').lower().strip()
                        if item_key == key_lower:
                            return item.get('content', 'Informa√ß√£o n√£o encontrada')
                
                return f"Informa√ß√£o sobre '{key}' n√£o encontrada. Tente: hor√°rios, regras, promo√ß√µes, endere√ßo, telefone."
            except Exception as e:
                error_msg = f"Erro ao buscar conhecimento: {e}"
                logger.error(error_msg)
                self._save_log_to_db('ERROR', error_msg, {'tool': 'get_business_knowledge', 'key': key})
                return "Erro ao buscar informa√ß√µes da empresa"
        
        @lc_tool("get_api_rules")
        def get_api_rules() -> str:
            """Retorna as regras da API Trinks para a empresa"""
            try:
                # Usar TrinksRules diretamente
                rules = self.trinks_rules.get_api_rules()
                return f"Regras da API Trinks: Email obrigat√≥rio: {rules.get('email_required', False)}, WaId obrigat√≥rio: {rules.get('waid_required', True)}"
            except Exception as e:
                error_msg = f"Erro ao buscar regras da API: {e}"
                logger.error(error_msg)
                self._save_log_to_db('ERROR', error_msg, {'tool': 'get_api_rules'})
                return "Erro ao buscar regras da API"
        
        @lc_tool("get_available_flows")
        def get_available_flows() -> str:
            """Retorna os fluxos dispon√≠veis para a API Trinks"""
            try:
                # Usar TrinksRules diretamente
                rules = self.trinks_rules.get_api_rules()
                flows = rules.get('fluxos_por_intencao', {})
                
                if flows:
                    flow_list = []
                    for intent, flow in flows.items():
                        flow_list.append(f"- {intent}: {flow['descricao']}")
                    
                    return f"Fluxos dispon√≠veis para Trinks:\n" + "\n".join(flow_list)
                else:
                    return f"Nenhum fluxo configurado para Trinks"
            except Exception as e:
                error_msg = f"Erro ao buscar fluxos: {e}"
                logger.error(error_msg)
                self._save_log_to_db('ERROR', error_msg, {'tool': 'get_available_flows'})
                return "Erro ao buscar fluxos dispon√≠veis"
        
        @lc_tool("search_client")
        def search_client(identifier: str, identifier_type: str = "cpf") -> str:
            """Busca cliente por CPF, telefone ou nome usando as rules da API"""
            try:
                # Obter regras da API Trinks
                rules_instance = self.trinks_rules
                if not rules_instance:
                    return "API n√£o configurada para esta empresa"
                
                # Executar busca usando as rules (que chamam as tools)
                if hasattr(rules_instance, 'execute_client_search'):
                    result = rules_instance.execute_client_search(identifier, identifier_type)
                    
                    if result.get('success'):
                        return result.get('message', 'Cliente encontrado')
                    else:
                        return f"Erro: {result.get('error', 'Busca falhou')}"
                else:
                    return "API n√£o suporta busca de clientes"
                    
            except Exception as e:
                logger.error(f"Erro ao buscar cliente: {e}")
                return f"Erro ao buscar cliente: {str(e)}"
        
        @lc_tool("check_availability")
        def check_availability(professional: str = None, service: str = None, date: str = None) -> str:
            """Verifica disponibilidade usando as rules da API"""
            try:
                # Obter regras da API Trinks
                rules_instance = self.trinks_rules
                if not rules_instance:
                    return "API n√£o configurada para esta empresa"
                
                # Executar verifica√ß√£o usando as rules (que chamam as tools)
                if hasattr(rules_instance, 'execute_availability_check'):
                    result = rules_instance.execute_availability_check(professional, service, date)
                    
                    if result.get('success'):
                        return result.get('message', 'Verifica√ß√£o conclu√≠da')
                    else:
                        return f"Erro: {result.get('error', 'Verifica√ß√£o falhou')}"
                else:
                    return "API n√£o suporta verifica√ß√£o de disponibilidade"
                    
            except Exception as e:
                logger.error(f"Erro ao verificar disponibilidade: {e}")
                return f"Erro ao verificar disponibilidade: {str(e)}"
        
        @lc_tool("book_appointment")
        def book_appointment(professional: str, service: str, date: str, time: str, client_name: str) -> str:
            """Agenda uma consulta usando as rules da API"""
            try:
                # Obter regras da API Trinks
                rules_instance = self.trinks_rules
                if not rules_instance:
                    return "API n√£o configurada para esta empresa"
                
                # Executar agendamento usando as rules (que chamam as tools)
                if hasattr(rules_instance, 'execute_reservation_creation'):
                    result = rules_instance.execute_reservation_creation(professional, service, date, time, client_name)
                    
                    if result.get('success'):
                        return result.get('message', 'Agendamento realizado')
                    else:
                        return f"Erro: {result.get('error', 'Agendamento falhou')}"
                else:
                    return "API n√£o suporta agendamento"
                    
            except Exception as e:
                logger.error(f"Erro ao agendar consulta: {e}")
                return f"Erro ao agendar consulta: {str(e)}"
        
        @lc_tool("execute_flow")
        def execute_flow(intent: str, **kwargs) -> str:
            """Executa um fluxo espec√≠fico baseado na inten√ß√£o usando as rules"""
            try:
                # Obter regras da API Trinks
                rules = self.trinks_rules.get_api_rules()
                flows = rules.get('fluxos_por_intencao', {})
                
                if intent not in flows:
                    return f"Inten√ß√£o '{intent}' n√£o suportada. Fluxos dispon√≠veis: {list(flows.keys())}"
                
                flow = flows[intent]
                required_fields = flow.get('campos_obrigatorios', [])
                
                # Verificar campos obrigat√≥rios
                missing_fields = []
                for field in required_fields:
                    if field not in kwargs:
                        missing_fields.append(field)
                
                if missing_fields:
                    return f"Campos obrigat√≥rios faltando para '{intent}': {missing_fields}"
                
                # Executar fluxo usando as rules apropriadas
                rules_instance = self.trinks_rules
                if rules_instance:
                    # Mapear inten√ß√£o para m√©todo da rule
                    if intent == "verificar_disponibilidade":
                        if hasattr(rules_instance, 'execute_availability_check'):
                            result = rules_instance.execute_availability_check(**kwargs)
                            return result.get('message', 'Fluxo executado')
                    elif intent == "agendar_consulta":
                        if hasattr(rules_instance, 'execute_reservation_creation'):
                            result = rules_instance.execute_reservation_creation(**kwargs)
                            return result.get('message', 'Fluxo executado')
                
                # Fallback: simular execu√ß√£o do fluxo
                steps = flow.get('passos', [])
                result = f"Executando fluxo '{intent}':\n"
                
                for step in steps:
                    result += f"‚úÖ {step}\n"
                
                result += f"\nDados recebidos: {kwargs}"
                return result
                
            except Exception as e:
                logger.error(f"Erro ao executar fluxo: {e}")
                return f"Erro ao executar fluxo '{intent}': {str(e)}"
        
        tools = [
            get_business_knowledge,
            get_api_rules,
            get_available_flows,
            search_client,
            check_availability,
            book_appointment,
            execute_flow
        ]
        
        return tools
    
    def process_message(self, message: str, waid: str, context: Dict[str, Any] = None) -> str:
        """Processa uma mensagem recebida e retorna a resposta apropriada"""
        try:
            logger.info(f"Processando mensagem para waid {waid}")
            
            # ‚úÖ CARREGAR contexto do cache por waid
            self._load_conversation_context(waid)
            
            # ‚úÖ ARQUITETURA: Preparar contexto com hist√≥rico para as Rules
            if context is None:
                context = {}
            
            # ‚úÖ OBTER HIST√ìRICO da mem√≥ria LangChain (√∫ltimas 10 mensagens)
            conversation_history = []
            if self.memory.chat_memory.messages:
                conversation_history = self.memory.chat_memory.messages[-10:]
                logger.info(f"üìö Hist√≥rico da conversa: {len(conversation_history)} mensagens")
            
            # ‚úÖ ADICIONAR ao contexto para as Rules
            context['conversation_history'] = conversation_history
            context['waid'] = waid
            
            # ‚úÖ NOVO: PASSAR CACHE TEMPOR√ÅRIO como contexto
            if waid in SmartAgent._conversation_cache:
                cached_data = SmartAgent._conversation_cache[waid]
                if 'extracted_data' in cached_data:
                    extracted_data = cached_data['extracted_data']
                    
                    # ‚úÖ PASSAR cache tempor√°rio como contexto
                    if 'temp_professional_cache' in extracted_data:
                        context['temp_professional_cache'] = extracted_data['temp_professional_cache']
                        context['temp_cache_expiry'] = extracted_data['temp_cache_expiry']
                        logger.info(f"üîÑ Cache tempor√°rio passado para TrinksRules: {len(extracted_data['temp_professional_cache'])} profissionais")
            
            # ‚úÖ ARQUITETURA UNIFICADA: Detectar inten√ß√£o e extrair dados em uma √∫nica chamada LLM
            parsed_result = self.trinks_rules.detect_intent_and_extract(message, context, self.empresa_config)
            intent = parsed_result.get("intent", "general")
            extracted_data = parsed_result.get("extracted", {})
            cache_instructions = parsed_result.get("cache_instructions", {})
            logger.info(f"Resultado do parsing unificado via Rules - Intent: {intent}, Dados: {extracted_data}")
            logger.info(f"üìã Cache instructions recebidas: {cache_instructions}")

            # ‚úÖ EXECUTAR CACHE_INSTRUCTIONS ANTES de salvar no contexto
            if cache_instructions:
                logger.info(f"üßπ Executando cache_instructions antes de salvar no cache...")
                self._execute_cache_instructions(cache_instructions, waid)
            else:
                logger.info(f"üìã Nenhuma cache_instruction para executar")

            # ‚úÖ EXECUTAR MESCLAGEM INTELIGENTE para preservar contexto
            logger.info(f"üîÑ Executando mesclagem inteligente para preservar contexto...")
            merged_data = self._merge_extracted_with_cache(extracted_data, waid)
            logger.info(f"‚úÖ Dados mesclados com contexto: {merged_data}")

            # ‚úÖ Disponibilizar no contexto para pr√≥ximos passos/execu√ß√£o
            context['extracted_data'] = merged_data
            context['intent'] = intent

            # ‚úÖ ARQUITETURA: 3) LLM de PR√ìXIMOS PASSOS (Rules orquestra, Tools operam)
            try:
                next_steps = self.trinks_rules.decide_next_steps(intent, context, self.empresa_config)
            except Exception as _e:
                logger.warning(f"Falha ao decidir pr√≥ximos passos: {_e}")
                next_steps = {"action": "ask_user", "agent_response": "Poderia detalhar, por favor?"}

            # ‚úÖ NOVA ARQUITETURA: Extrair regras de neg√≥cio dos pr√≥ximos passos
            business_rules = next_steps.get('business_rules', [])
            
            logger.info(f"üìã Regras de neg√≥cio recebidas: {business_rules}")
            
            # ‚úÖ Disponibilizar regras de neg√≥cio no contexto para uso futuro
            context['business_rules'] = business_rules
            
            # ‚úÖ DEBUG: Log da action recebida
            action = next_steps.get("action")
            logger.info(f"üéØ Action recebida: {action}")
            
            # ‚úÖ DEBUG: Verificar se precisa executar action
            if action:
                logger.info(f"üîß Executando action: {action}")
                
                # ‚úÖ NOVO: Verificar se action √© array ou string
                if isinstance(action, list):
                    logger.info(f"üîÑ Action √© array com {len(action)} passos: {action}")
                    
                    # ‚úÖ NOVO: Verificar se √© array com apenas "ask_user"
                    if len(action) == 1 and action[0] == "ask_user":
                        logger.info("üë§ Array cont√©m apenas ask_user - tratando como caso especial")
                        # ‚úÖ ask_user vai DIRETO para o prompt da empresa
                        result = self._handle_ask_user_direct(business_rules, merged_data, next_steps, context, intent)
                    else:
                        logger.info("üîß Array cont√©m tools - executando m√∫ltiplas actions")
                        result = self._execute_multiple_actions(action, merged_data, next_steps, context)
                else:
                    logger.info(f"üîß Action √© string √∫nica: {action}")
                    
                    # ‚úÖ NOVO: Verificar se string √© "ask_user"
                    if action == "ask_user":
                        logger.info("üë§ Action √© ask_user - tratando como caso especial")
                        # ‚úÖ ask_user vai DIRETO para o prompt da empresa
                        result = self._handle_ask_user_direct(business_rules, merged_data, next_steps, context, intent)
                    else:
                        logger.info("üîß Action √© tool - executando action √∫nica")
                        result = self._execute_single_action(action, merged_data, context)
                
                # ‚úÖ NOVO: Analisar resultados e gerar resposta formatada
                # ‚úÖ Verificar se √© ask_user para evitar an√°lise desnecess√°ria
                if isinstance(action, list) and len(action) == 1 and action[0] == "ask_user":
                    logger.info("üë§ ask_user detectado - pulando an√°lise desnecess√°ria")
                    # ‚úÖ ask_user j√° retorna resposta formatada pronta (string)
                    # result j√° √© a string formatada, n√£o precisa de .get()
                elif isinstance(action, str) and action == "ask_user":
                    logger.info("üë§ ask_user detectado - pulando an√°lise desnecess√°ria")
                    # ‚úÖ ask_user j√° retorna resposta formatada pronta (string)
                    # result j√° √© a string formatada, n√£o precisa de .get()
                elif isinstance(result, dict) and result.get('status') != 'erro':
                    # ‚úÖ Verificar se √© resultado de m√∫ltiplas actions
                    if result.get('status') == 'actions_executadas':
                        logger.info("üîß M√∫ltiplas actions executadas - analisando resultados completos...")
                        
                        # ‚úÖ Usar TODOS os resultados das actions
                        analysis_data = {
                            'results': result.get('results', {}),
                            'extracted_data': merged_data,
                            'business_rules': business_rules,
                            'context': context
                        }
                        
                        # ‚úÖ Chamar direto a LLM principal (sem an√°lise intermedi√°ria)
                        logger.info("‚úÖ Chamando direto a LLM principal com prompt da empresa...")
                        formatted_response = self._analyze_with_company_llm(
                            f"Processar intent: {intent}",
                            analysis_data
                        )
                        logger.info(f"‚úÖ Resposta formatada pela empresa: {formatted_response}")
                        result = formatted_response
                    else:
                        logger.info("üîß Action √∫nica executada - analisando resultado...")
                        
                        # ‚úÖ Para action √∫nica, chamar direto a LLM principal
                        analysis_data = {
                            'results': {'single_action': result},
                            'extracted_data': merged_data,
                            'business_rules': business_rules,
                            'context': context
                        }
                        
                        # ‚úÖ Chamar direto a LLM principal (sem an√°lise intermedi√°ria)
                        logger.info("‚úÖ Chamando direto a LLM principal com prompt da empresa...")
                        formatted_response = self._analyze_with_company_llm(
                            f"Processar intent: {intent}",
                            analysis_data
                        )
                        logger.info(f"‚úÖ Resposta formatada pela empresa: {formatted_response}")
                        result = formatted_response
                else:
                    # ‚úÖ FALLBACK: Se n√£o houver regras de neg√≥cio, usar resultado bruto
                    logger.info("üîÑ Usando resultado bruto (sem regras de neg√≥cio)")
                    if isinstance(result, dict):
                        result = f"‚úÖ Actions executadas com sucesso. Status: {result.get('status')}"
                    else:
                        result = str(result)
            else:
                # Para manter simplicidade: usar a mensagem pronta da LLM de pr√≥ximos passos
                result = next_steps.get("agent_response") or "Certo, me diga por favor o pr√≥ximo detalhe (data/hor√°rio/CPF)."
            
            # ‚úÖ ADICIONAR mensagem atual √† mem√≥ria LangChain
            self.memory.chat_memory.add_user_message(message)
            
            # ‚úÖ ADICIONAR resposta do bot √† mem√≥ria LangChain
            self.memory.chat_memory.add_ai_message(result)
            
            # ‚úÖ SALVAR contexto no cache por waid (INCLUINDO MENSAGENS + DADOS EXTRA√çDOS)
            try:
                # Preferir enriched_data consolidado com ids quando dispon√≠vel
                enriched = getattr(self, '_last_enriched_extracted_data', None)
                data_to_cache = enriched if isinstance(enriched, dict) and enriched else extracted_data
            except Exception:
                data_to_cache = extracted_data
            self._save_conversation_context(waid, data_to_cache)
            
            return result
            
        except Exception as e:
            logger.error(f"Erro ao processar mensagem: {e}")
            return self._generate_response_with_company_prompt(
                "erro_geral",
                {'error': f"Erro ao processar mensagem: {str(e)}", 'context': context},
                context
            )
    
    
    

    
    # ‚úÖ M√âTODO REMOVIDO: _execute_intent_flow nunca foi usado
    # Todo o fluxo principal usa process_message() que funciona perfeitamente
    
    def _generate_general_response(self, message: str, context: Dict[str, Any] = None) -> str:
        """Gera resposta para mensagens gerais usando prompt da empresa"""
        try:
            # Usar prompt da empresa para resposta geral
            return self._generate_response_with_company_prompt(
                "resposta_geral",
                {'message': message, 'context': context},
                context
            )
            
        except Exception as e:
            logger.error(f"Erro ao gerar resposta geral: {e}")
            return self._generate_response_with_company_prompt(
                "erro_geral",
                {'error': f"Erro ao gerar resposta geral: {str(e)}", 'context': context},
                context
            )
    
    def get_conversation_summary(self) -> Dict[str, Any]:
        """Retorna um resumo do estado atual da conversa"""
        return {
            "status": "active",
            "memory_size": len(self.memory.chat_memory.messages),
            "tools_available": len(self.tools),
            "empresa": self.empresa_config.get('nome', 'N/A')
        }
    
    def _load_conversation_context(self, waid: str) -> None:
        """Carrega contexto de conversa do cache global"""
        if waid in SmartAgent._conversation_cache:
            cached_data = SmartAgent._conversation_cache[waid]
            logger.info(f"Carregando contexto para waid {waid}: {len(cached_data.get('messages', []))} mensagens")
            
            # ‚úÖ CORRE√á√ÉO: Acessar a estrutura correta do cache
            if isinstance(cached_data, dict) and 'messages' in cached_data:
                cached_messages = cached_data['messages']
                # Log resumido do extracted_data salvo no cache
                try:
                    ed = cached_data.get('extracted_data', {}) or {}
                    ed_summary = {
                        'profissional': ed.get('profissional'),
                        'profissional_id': ed.get('profissional_id'),
                        'procedimento': ed.get('procedimento'),
                        'servico_id': ed.get('servico_id'),
                        'data': ed.get('data'),
                        'horario': ed.get('horario')
                    }
                    logger.info(f"üóÑÔ∏è extracted_data do cache (load) para {waid}: {ed_summary}")
                except Exception as _e:
                    logger.warning(f"Falha ao logar extracted_data do cache: {_e}")
                # Restaurar mensagens na mem√≥ria
                for msg in cached_messages:
                    if msg.get('type') == 'human':
                        self.memory.chat_memory.add_user_message(msg['content'])
                    elif msg.get('type') == 'ai':
                        self.memory.chat_memory.add_ai_message(msg['content'])
            else:
                # ‚úÖ COMPATIBILIDADE: Fallback para formato antigo
                logger.warning(f"Formato de cache inesperado para waid {waid}, tentando fallback")
                if isinstance(cached_data, list):
                    # Formato antigo: lista direta de mensagens
                    for msg in cached_data:
                        if msg.get('type') == 'human':
                            self.memory.chat_memory.add_user_message(msg['content'])
                        elif msg.get('type') == 'ai':
                            self.memory.chat_memory.add_ai_message(msg['content'])
                else:
                    logger.error(f"Formato de cache inv√°lido para waid {waid}: {type(cached_data)}")
        else:
            logger.info(f"Primeira mensagem para waid {waid}, criando novo contexto")
    
    def _save_conversation_context(self, waid: str, extracted_data: Dict[str, Any] = None) -> None:
        """Salva contexto de conversa no cache global"""
        messages = []
        for msg in self.memory.chat_memory.messages:
            if hasattr(msg, 'type') and msg.type == 'human':
                messages.append({'type': 'human', 'content': msg.content})
            elif hasattr(msg, 'type') and msg.type == 'ai':
                messages.append({'type': 'ai', 'content': msg.content})
            else:
                # Fallback para diferentes tipos de mensagem
                messages.append({'type': 'unknown', 'content': str(msg.content)})
        
        # ‚úÖ Salvar mensagens + dados extra√≠dos
        cache_data = {
            'messages': messages,
            'extracted_data': extracted_data or {}
        }
        
        SmartAgent._conversation_cache[waid] = cache_data
        logger.info(f"üóÑÔ∏è Contexto + dados extra√≠dos salvos para waid {waid}: {len(messages)} mensagens + {len(extracted_data) if extracted_data else 0} campos")
        try:
            ed = extracted_data or {}
            ed_summary = {
                'profissional': ed.get('profissional'),
                'profissional_id': ed.get('profissional_id'),
                'procedimento': ed.get('procedimento'),
                'servico_id': ed.get('servico_id'),
                'data': ed.get('data'),
                'horario': ed.get('horario')
            }
            logger.info(f"üóÑÔ∏è extracted_data salvo (save) para {waid}: {ed_summary}")
        except Exception as _e:
            logger.warning(f"Falha ao logar extracted_data salvo: {_e}")
    
    def _update_cache_from_instructions(self, cache_instructions: Dict[str, Any], extracted_data: Dict[str, Any]) -> None:
        """‚úÖ NOVA FUN√á√ÉO: Atualiza cache seguindo instru√ß√µes das Rules"""
        try:
            if "update_fields" in cache_instructions:
                update_fields = cache_instructions["update_fields"]
                logger.info(f"üìã Atualizando cache com instru√ß√µes: {update_fields}")
                
                # ‚úÖ GARANTIR que _last_enriched_extracted_data seja inicializado
                if not hasattr(self, '_last_enriched_extracted_data') or self._last_enriched_extracted_data is None:
                    self._last_enriched_extracted_data = extracted_data.copy()
                    logger.info(f"‚úÖ _last_enriched_extracted_data inicializado com: {extracted_data}")
                
                for field, value in update_fields.items():
                    extracted_data[field] = value
                    logger.info(f"‚úÖ Campo '{field}' atualizado para '{value}' no cache")
                
                # Atualizar tamb√©m o atributo interno para manter sincronizado
                for field, value in update_fields.items():
                    self._last_enriched_extracted_data[field] = value
                    logger.info(f"‚úÖ Campo '{field}' atualizado para '{value}' no enriched_data")
                        
        except Exception as e:
            logger.error(f"‚ùå Erro ao atualizar cache com instru√ß√µes: {e}")
    
    def _execute_cache_instructions(self, cache_instructions: Dict[str, Any], waid: str) -> None:
        """‚úÖ NOVA FUN√á√ÉO: Executa instru√ß√µes de cache (clear_fields) antes de salvar"""
        try:
            if not cache_instructions or not isinstance(cache_instructions, dict):
                logger.info("üìã Nenhuma instru√ß√£o de cache para executar")
                return
            
            clear_fields = cache_instructions.get("clear_fields", [])
            if not clear_fields:
                logger.info("üìã Nenhum campo para limpar do cache")
                return
            
            logger.info(f"üßπ Executando cache_instructions: clear_fields = {clear_fields}")
            
            # ‚úÖ Verificar se existe cache para este waid
            if waid not in SmartAgent._conversation_cache:
                logger.info(f"üìã Cache n√£o encontrado para waid {waid}, nada para limpar")
                return
            
            cached_data = SmartAgent._conversation_cache[waid]
            if not isinstance(cached_data, dict) or 'extracted_data' not in cached_data:
                logger.info(f"üìã Estrutura de cache inv√°lida para waid {waid}")
                return
            
            extracted_data = cached_data['extracted_data']
            if not isinstance(extracted_data, dict):
                logger.info(f"üìã extracted_data inv√°lido para waid {waid}")
                return
            
            # ‚úÖ Limpar campos especificados
            cleared_count = 0
            for field in clear_fields:
                if field in extracted_data:
                    old_value = extracted_data[field]
                    extracted_data[field] = None
                    cleared_count += 1
                    logger.info(f"üßπ Campo '{field}' limpo do cache (era: {old_value})")
                else:
                    logger.info(f"üìã Campo '{field}' n√£o encontrado no cache, nada para limpar")
            
            # ‚úÖ Atualizar cache global
            SmartAgent._conversation_cache[waid]['extracted_data'] = extracted_data
            
            # ‚úÖ Atualizar tamb√©m o atributo interno se existir
            if hasattr(self, '_last_enriched_extracted_data') and self._last_enriched_extracted_data:
                for field in clear_fields:
                    if field in self._last_enriched_extracted_data:
                        old_value = self._last_enriched_extracted_data[field]
                        self._last_enriched_extracted_data[field] = None
                        logger.info(f"üßπ Campo '{field}' limpo do _last_enriched_extracted_data (era: {old_value})")
            
            logger.info(f"‚úÖ Cache limpo com sucesso: {cleared_count} campos limpos")
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao executar cache_instructions: {e}")
            logger.error(f"cache_instructions: {cache_instructions}, waid: {waid}")
    
    def _merge_extracted_with_cache(self, extracted_data: Dict[str, Any], waid: str) -> Dict[str, Any]:
        """‚úÖ NOVA FUN√á√ÉO: Mescla dados extra√≠dos com cache atual de forma inteligente"""
        try:
            logger.info(f"üîÑ Executando mesclagem inteligente para waid {waid}")
            
            # ‚úÖ Verificar se existe cache para este waid
            if waid not in SmartAgent._conversation_cache:
                logger.info(f"üìã Cache n√£o encontrado para waid {waid}, retornando dados extra√≠dos")
                return extracted_data
            
            cached_data = SmartAgent._conversation_cache[waid]
            if not isinstance(cached_data, dict) or 'extracted_data' not in cached_data:
                logger.info(f"üìã Estrutura de cache inv√°lida para waid {waid}, retornando dados extra√≠dos")
                return extracted_data
            
            current_cache = cached_data['extracted_data']
            if not isinstance(current_cache, dict):
                logger.info(f"üìã extracted_data inv√°lido para waid {waid}, retornando dados extra√≠dos")
                return extracted_data
            
            # ‚úÖ MESCLAGEM INTELIGENTE: Atualiza apenas o que mudou, mant√©m o resto
            merged_cache = current_cache.copy()
            updated_count = 0
            
            for field, new_value in extracted_data.items():
                if new_value is not None and new_value != "" and new_value != "null":
                    old_value = merged_cache.get(field)
                    if old_value != new_value:
                        merged_cache[field] = new_value
                        updated_count += 1
                        logger.info(f"üîÑ Campo '{field}' atualizado: '{old_value}' ‚Üí '{new_value}'")
                    else:
                        logger.info(f"üìã Campo '{field}' mantido: '{old_value}' (sem mudan√ßa)")
                else:
                    logger.info(f"üìã Campo '{field}' ignorado: valor inv√°lido")
            
            # ‚úÖ Atualizar cache global
            SmartAgent._conversation_cache[waid]['extracted_data'] = merged_cache
            
            # ‚úÖ Atualizar tamb√©m o atributo interno se existir
            if hasattr(self, '_last_enriched_extracted_data') and self._last_enriched_extracted_data:
                for field, value in extracted_data.items():
                    if value is not None and value != "" and value != "null":
                        self._last_enriched_extracted_data[field] = value
            
            # ‚úÖ REGRA DE EXPIRA√á√ÉO AUTOM√ÅTICA: Cache tempor√°rio expira ap√≥s 2 mensagens
            if 'temp_cache_expiry' in merged_cache:
                # ‚úÖ PROTE√á√ÉO: Verificar se o valor √© num√©rico antes de fazer opera√ß√£o matem√°tica
                expiry_value = merged_cache['temp_cache_expiry']
                if isinstance(expiry_value, (int, float)):
                    merged_cache['temp_cache_expiry'] = expiry_value - 1
                    if merged_cache['temp_cache_expiry'] <= 0:
                        # Cache expirou ‚Üí limpar automaticamente
                        if 'temp_professional_cache' in merged_cache:
                            del merged_cache['temp_professional_cache']
                        del merged_cache['temp_cache_expiry']
                        logger.info("üßπ Cache tempor√°rio expirado e limpo automaticamente")
                    else:
                        logger.info(f"‚è∞ Cache tempor√°rio expira em {merged_cache['temp_cache_expiry']} mensagens")
                else:
                    # Se n√£o for num√©rico, converter para n√∫mero ou usar valor padr√£o
                    logger.warning(f"‚ö†Ô∏è temp_cache_expiry n√£o √© num√©rico: {expiry_value} (tipo: {type(expiry_value)})")
                    merged_cache['temp_cache_expiry'] = 1  # Reset para 1 mensagem
                    logger.info("‚è∞ Cache tempor√°rio resetado para 1 mensagem")
            
            logger.info(f"‚úÖ Mesclagem inteligente conclu√≠da: {updated_count} campos atualizados")
            logger.info(f"üéØ Cache final: {merged_cache}")
            
            return merged_cache
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao executar mesclagem inteligente: {e}")
            logger.error(f"extracted_data: {extracted_data}, waid: {waid}")
            # Fallback: retornar dados extra√≠dos sem mesclar
            return extracted_data
    
    def _execute_availability_check(self, extracted_data: Dict[str, Any], context: Dict[str, Any]) -> str:
        """Executa verifica√ß√£o de disponibilidade com suporte a busca por profissional OU procedimento"""
        try:
            # Obter regras expandidas da API
            api_rules = self.trinks_rules.get_availability_check_rules_expanded()
            if not api_rules:
                return "Erro: Regras de disponibilidade n√£o configuradas"
            
            # Validar requisi√ß√£o
            validation = self.trinks_rules.validate_availability_request(extracted_data)
            if not validation.get('valid'):
                # N√ÉO retornar erro direto - usar prompt principal do admin
                logger.info(f"Valida√ß√£o falhou: {validation.get('error')} - usando prompt principal do admin")
                return self._generate_response_with_company_prompt(
                    "verificar_disponibilidade",
                    {
                        'error': validation.get('error'),
                        'extracted_data': extracted_data,
                        'missing_fields': validation.get('missing_fields', []),
                        'context': context
                    },
                    context
                )
            
            search_type = validation.get('search_type')
            logger.info(f"Executando fluxo verificar_disponibilidade com tipo: {search_type}")
            
            # ‚öôÔ∏è Previous data do cache (ids j√° resolvidos, etc.)
            previous_data = {}
            try:
                waid = context.get('waid') if context else None
                if waid and hasattr(SmartAgent, '_conversation_cache') and waid in SmartAgent._conversation_cache:
                    cached = SmartAgent._conversation_cache.get(waid, {})
                    if isinstance(cached, dict):
                        previous_data = cached.get('extracted_data', {}) or {}
            except Exception as _e:
                logger.warning(f"N√£o foi poss√≠vel obter previous_data do cache: {_e}")

            # Executar fluxo expandido √∫nico
            return self._execute_expanded_availability_check(extracted_data, context, api_rules, previous_data)
                
        except Exception as e:
            logger.error(f"Erro ao executar verifica√ß√£o de disponibilidade: {e}")
            # N√ÉO retornar erro direto - usar prompt principal do admin
            return self._generate_response_with_company_prompt(
                "verificar_disponibilidade",
                {
                    'error': f"Erro ao verificar disponibilidade: {str(e)}",
                    'context': context
                },
                context
            )
    
    def _execute_expanded_availability_check(self, data: Dict[str, Any], context: Dict[str, Any], api_rules: Dict[str, Any], previous_data: Dict[str, Any] = None) -> str:
        """Executa verifica√ß√£o de disponibilidade usando arquitetura Rules ‚Üí Tools ‚Üí Integrations"""
        try:
            logger.info("Executando fluxo expandido de verifica√ß√£o de disponibilidade")
            
            # 1. OBTER REGRAS E PASSOS
            rules_instance = self.trinks_rules
            if not rules_instance:
                return "Erro: N√£o foi poss√≠vel obter as regras da API"
            
            # Obter passos configurados via Rules (arquitetura correta)
            passos = rules_instance.get_availability_flow_steps(data, self.empresa_config, previous_data or {})
            logger.info(f"üìã Fluxo configurado via Rules: {passos}")
            
            # 2. EXECUTAR CADA PASSO VIA RULES (que chamam Tools)
            resultado = {}
            
            for i, passo in enumerate(passos, 1):
                logger.info(f"PASSO {i}: Executando {passo} via Rules...")
                
                try:
                    if passo == "extrair_dados":
                        # Dados j√° extra√≠dos pelo Smart Agent
                        resultado[passo] = {"status": "concluido", "dados": data}
                        logger.info(f"PASSO {i}: {passo} ‚úì")
                        
                    elif passo == "validar_campos":
                        # Validar usando regras
                        validation = rules_instance.validate_availability_request(data)
                        resultado[passo] = validation
                        if not validation.get('valid'):
                            return self._generate_response_with_company_prompt(
                                "verificar_disponibilidade",
                                {'error': validation.get('error'), 'context': context},
                                context
                            )
                        logger.info(f"PASSO {i}: {passo} ‚úì")
                        
                    elif passo == "buscar_profissional":
                        # Executar via Rules (que chama Tools)
                        step_result = rules_instance.execute_step(passo, data, self.empresa_config)
                        resultado[passo] = step_result
                        
                        if step_result.get('status') == 'erro':
                            return self._generate_response_with_company_prompt(
                                "verificar_disponibilidade",
                                {'error': step_result.get('error'), 'context': context},
                                context
                            )
                        logger.info(f"PASSO {i}: {passo} ‚úì - {step_result.get('status')}")
                        
                    elif passo == "fazer_match_profissional":
                        # Match j√° feito no passo anterior
                        resultado[passo] = {"status": "concluido"}
                        logger.info(f"PASSO {i}: {passo} ‚úì")
                        
                    elif passo == "buscar_servico":
                        # Executar via Rules (que chama Tools)
                        step_result = rules_instance.execute_step(passo, data, self.empresa_config)
                        resultado[passo] = step_result
                        
                        if step_result.get('status') == 'erro':
                            return self._generate_response_with_company_prompt(
                                "verificar_disponibilidade",
                                {'error': step_result.get('error'), 'context': context},
                                context
                            )
                        
                        # Log mais detalhado para buscar_servico
                        if step_result.get('id'):
                            logger.info(f"PASSO {i}: {passo} ‚úì - Servi√ßo encontrado: {step_result.get('nome')} (ID: {step_result.get('id')})")
                        else:
                            logger.info(f"PASSO {i}: {passo} ‚úì - {step_result.get('status', 'Resultado')}")
                        
                    elif passo == "fazer_match_servico":
                        # Match j√° feito no passo anterior
                        resultado[passo] = {"status": "concluido"}
                        logger.info(f"PASSO {i}: {passo} ‚úì")
                        
                    elif passo == "verificar_disponibilidade":
                        # Preparar dados para verifica√ß√£o
                        servico_info = resultado.get('buscar_servico', {})
                        profissional_info = resultado.get('buscar_profissional', {})
                        
                        # Extrair IDs
                        servico_id = None
                        profissional_id = None
                        
                        if servico_info.get('id'):
                            servico_id = servico_info['id']
                        elif servico_info.get('result', {}).get('id'):
                            servico_id = servico_info['result']['id']
                        
                        if profissional_info.get('id'):
                            profissional_id = profissional_info['id']
                        elif profissional_info.get('result', {}).get('id'):
                            profissional_id = profissional_info['result']['id']

                        # Fallback: usar IDs do previous_data se n√£o foram obtidos neste fluxo
                        if not servico_id and isinstance(previous_data, dict):
                            servico_id = previous_data.get('servico_id') or servico_id
                        if not profissional_id and isinstance(previous_data, dict):
                            profissional_id = previous_data.get('profissional_id') or profissional_id
                        logger.info(f"üóÑÔ∏è IDs usados para verifica√ß√£o: servico_id={servico_id} | profissional_id={profissional_id}")
                        
                        # Dados para execu√ß√£o
                        execution_data = {
                            'servico_id': servico_id,
                            'data': data.get('data'),
                            'profissional_id': profissional_id
                        }
                        logger.info(f"üóÑÔ∏è execution_data enviado para verificar_disponibilidade: {execution_data}")
                        # Preparar enriched_data parcial com ids resolvidos at√© aqui
                        try:
                            enriched_data = dict(data)
                            if servico_id:
                                enriched_data['servico_id'] = servico_id
                            if profissional_id:
                                enriched_data['profissional_id'] = profissional_id
                            # Manter data informada
                            if data.get('data'):
                                enriched_data['data'] = data.get('data')
                            # Disponibilizar para quem salvar mais tarde
                            self._last_enriched_extracted_data = enriched_data
                        except Exception as _e:
                            logger.warning(f"Falha ao montar enriched_data parcial: {_e}")

                        # Executar via Rules (que chama Tools)
                        step_result = rules_instance.execute_step(passo, execution_data, self.empresa_config)
                        resultado[passo] = step_result
                        
                        if step_result.get('status') == 'erro':
                            return self._generate_response_with_company_prompt(
                                "verificar_disponibilidade",
                                {'error': step_result.get('error'), 'context': context},
                                context
                            )
                        logger.info(f"PASSO {i}: {passo} ‚úì - Disponibilidade verificada")
                        
                    elif passo == "validar_slots":
                        # Preparar dados para valida√ß√£o
                        disponibilidade = resultado.get('verificar_disponibilidade', {})
                        servico_info = resultado.get('buscar_servico', {})
                        
                        # Dados para execu√ß√£o
                        execution_data = {
                            'disponibilidade': disponibilidade,
                            'servico_info': servico_info
                        }
                        
                        # Executar via Rules (que chama Tools)
                        step_result = rules_instance.execute_step(passo, execution_data, self.empresa_config)
                        resultado[passo] = step_result
                        
                        if step_result.get('status') == 'erro':
                            logger.warning(f"PASSO {i}: {passo} ‚ö†Ô∏è - Erro na valida√ß√£o: {step_result.get('error')}")
                        else:
                            logger.info(f"PASSO {i}: {passo} ‚úì - Slots validados")
                        
                    elif passo == "gerar_resposta":
                        # Gerar resposta final
                        resultado[passo] = {"status": "concluido"}
                        logger.info(f"PASSO {i}: {passo} ‚úì")
                        
                    else:
                        logger.warning(f"PASSO {i}: {passo} ‚ö†Ô∏è - Passo n√£o implementado")
                        resultado[passo] = {"status": "nao_implementado"}
                        
                except Exception as e:
                    logger.error(f"Erro no PASSO {i} ({passo}): {e}")
                    resultado[passo] = {"status": "erro", "error": str(e)}
                    return self._generate_response_with_company_prompt(
                        "verificar_disponibilidade",
                        {'error': f"Erro no passo {passo}: {str(e)}", 'context': context},
                        context
                    )
            
            # 3. ‚úÖ NOVA ARQUITETURA: Analisar resultados com regras de neg√≥cio
            logger.info("üéØ Todos os passos executados com sucesso via Rules ‚Üí Tools ‚Üí Integrations!")
            
            # ‚úÖ Obter regras de neg√≥cio do contexto
            business_rules = context.get('business_rules', []) if context else []
            logger.info(f"üìã Regras de neg√≥cio para an√°lise: {business_rules}")
            
            # ‚úÖ Atualizar enriched_data final com contexto de disponibilidade (ids, etc.)
            try:
                enriched_data = getattr(self, '_last_enriched_extracted_data', dict(data))
                # Se no resultado houver ids, manter
                bs = resultado.get('buscar_servico', {}) or {}
                bp = resultado.get('buscar_profissional', {}) or {}
                if isinstance(bs, dict):
                    sid = bs.get('servico_id') or bs.get('id') or (bs.get('result', {}) or {}).get('id')
                    if sid:
                        enriched_data['servico_id'] = sid
                if isinstance(bp, dict):
                    pid = bp.get('profissional_id') or bp.get('id') or (bp.get('result', {}) or {}).get('id')
                    if pid:
                        enriched_data['profissional_id'] = pid
                # Garantir data
                if data.get('data'):
                    enriched_data['data'] = data.get('data')
                self._last_enriched_extracted_data = enriched_data
            except Exception as _e:
                logger.warning(f"Falha ao consolidar enriched_data final: {_e}")

            # ‚úÖ NOVA ARQUITETURA: Chamar direto a LLM principal
            if business_rules:
                logger.info("üîç Chamando direto a LLM principal com prompt da empresa...")
                return self._generate_response_with_company_prompt(
                    "verificar_disponibilidade",
                    {
                        'results': resultado,
                        'business_rules': business_rules,
                        'context': context
                    },
                    context
                )
            
            # ‚úÖ FALLBACK: L√≥gica original se n√£o houver regras de neg√≥cio
            logger.info("üîÑ Usando l√≥gica padr√£o (fallback)")
            
            # Verificar se temos disponibilidade
            disponibilidade = resultado.get('verificar_disponibilidade', {})
            
            if disponibilidade and disponibilidade.get('available_slots'):
                horarios = disponibilidade.get('available_slots', [])
                servico = resultado.get('buscar_servico', {})
                profissional = resultado.get('buscar_profissional', {})
                
                dados_para_llm = {
                    'horarios_disponiveis': horarios,
                    'servico': servico,
                    'profissional': profissional,
                    'data': data.get('data'),
                    'context': context
                }
                
                return self._generate_response_with_company_prompt(
                    "verificar_disponibilidade",
                    dados_para_llm,
                    context
                )
            else:
                return self._generate_response_with_company_prompt(
                    "verificar_disponibilidade",
                    {
                        'error': "N√£o h√° hor√°rios dispon√≠veis para o servi√ßo solicitado",
                        'context': context
                    },
                    context
                )
                
        except Exception as e:
            logger.error(f"Erro ao executar fluxo expandido: {e}")
            return self._generate_response_with_company_prompt(
                "verificar_disponibilidade",
                {
                    'error': f"Erro ao verificar disponibilidade: {str(e)}",
                    'context': context
                },
                context
            )
    
    def _call_tool(self, tool_name: str, params: Dict[str, Any]) -> Dict[str, Any]:
        """Chama uma tool espec√≠fica via LangChain"""
        try:
            if tool_name in self.tools:
                logger.info(f"üîß Chamando tool: {tool_name}")
                result = self.tools[tool_name].invoke(params)
                return {"success": True, "result": result}
            else:
                logger.warning(f"Tool {tool_name} n√£o encontrada")
                return {"success": False, "error": f"Tool {tool_name} n√£o encontrada"}
        except Exception as e:
            logger.error(f"Erro ao chamar tool {tool_name}: {e}")
            return {"success": False, "error": str(e)}
    
    def _execute_reservation_creation(self, data: Dict[str, Any], context: Dict[str, Any]) -> str:
        """Executa cria√ß√£o de reserva - DELEGA para Rules"""
        try:
            logger.info(f"üìÖ Delegando agendar_consulta para Rules com dados: {data}")
            
            # Verificar se tem dados b√°sicos (j√° validados em verificar_disponibilidade)
            dados_basicos = ['profissional_id', 'servico_id', 'data', 'horario']
            dados_faltantes = [campo for campo in dados_basicos if not data.get(campo)]
            
            if dados_faltantes:
                return f"Para agendar, preciso das seguintes informa√ß√µes: {', '.join(dados_faltantes)}"
            
            # DELEGAR para Rules (que executam o fluxo completo)
            rules_instance = self.trinks_rules
            if not rules_instance:
                return "Erro: N√£o foi poss√≠vel obter as regras da API"
            
            resultado = rules_instance.execute_flow("agendar_consulta", data, self.empresa_config, context)
            
            # Se precisa perguntar algo ao usu√°rio, retornar a pergunta
            if resultado.get('status') in ['perguntar_cpf', 'perguntar_nome']:
                return self._generate_response_with_company_prompt(
                    "perguntar_dados",
                    {'message': resultado.get('message', 'Preciso de mais informa√ß√µes para continuar'), 'context': context},
                    context
                )
            
            # Se houve erro, retornar mensagem de erro
            if resultado.get('status') == 'erro':
                return self._generate_response_with_company_prompt(
                    "agendar_consulta",
                    {'error': resultado.get('error'), 'context': context},
                    context
                )
            
            # Se dados incompletos, retornar mensagem
            if resultado.get('status') == 'dados_incompletos':
                return f"Para agendar, preciso das seguintes informa√ß√µes: {', '.join(resultado.get('campos_faltantes', []))}"
            
            # Sucesso! Retornar resultado formatado
            if resultado.get('status') == 'sucesso':
                # Atualizar cache com dados do cliente e agendamento
                if resultado.get('cliente_id'):
                    data['cliente_id'] = resultado.get('cliente_id')
                if resultado.get('appointment_id'):
                    data['appointment_id'] = resultado.get('appointment_id')
                
                return self._generate_response_with_company_prompt(
                    "agendar_consulta",
                    resultado,
                    context
                )
            
            # Fallback
            return "Agendamento processado. Aguarde confirma√ß√£o."
            
        except Exception as e:
            logger.error(f"Erro ao executar cria√ß√£o de reserva: {e}")
            return self._generate_response_with_company_prompt(
                "agendar_consulta",
                {'error': f"Erro ao criar reserva: {str(e)}", 'context': context},
                context
            )
    
    def _execute_reservation_cancellation(self, data: Dict[str, Any], context: Dict[str, Any]) -> str:
        """Executa cancelamento de reserva"""
        try:
            if not data.get('data'):
                return self._generate_response_with_company_prompt(
                    "cancelar_consulta",
                    {'error': "Dados insuficientes para cancelamento", 'missing_fields': ['data'], 'context': context},
                    context
                )
            
            # Usar prompt da empresa para formatar resposta
            return self._generate_response_with_company_prompt(
                "cancelar_consulta",
                data,
                context
            )
            
        except Exception as e:
            logger.error(f"Erro ao cancelar reserva: {e}")
            return self._generate_response_with_company_prompt(
                "cancelar_consulta",
                {'error': f"Erro ao cancelar reserva: {str(e)}", 'context': context},
                context
            )
    
    def _execute_reservation_reschedule(self, data: Dict[str, Any], context: Dict[str, Any]) -> str:
        """Executa reagendamento de reserva"""
        try:
            if not data.get('data_atual') or not data.get('nova_data'):
                return self._generate_response_with_company_prompt(
                    "reagendar_consulta",
                    {'error': "Dados insuficientes para reagendamento", 'missing_fields': ['data_atual', 'nova_data'], 'context': context},
                    context
                )
            
            # Usar prompt da empresa para formatar resposta
            return self._generate_response_with_company_prompt(
                "reagendar_consulta",
                data,
                context
            )
            
        except Exception as e:
            logger.error(f"Erro ao reagendar reserva: {e}")
            return self._generate_response_with_company_prompt(
                "reagendar_consulta",
                {'error': f"Erro ao reagendar reserva: {str(e)}", 'context': context},
                context
            )
    
    def _call_trinks_api(self, endpoint: str, params: Dict[str, Any]) -> Dict[str, Any]:
        """Chama API Trinks real"""
        
        try:
            # Configura√ß√£o da API
            base_url = self.empresa_config.get('trinks_base_url')
            api_key = self.empresa_config.get('trinks_api_key')
            estabelecimento_id = self.empresa_config.get('trinks_estabelecimento_id')
            
            if not all([base_url, api_key, estabelecimento_id]):
                logger.error("Configura√ß√£o Trinks incompleta")
                return {"error": "Configura√ß√£o Trinks incompleta"}
            
            # Headers
            headers = {
                'X-API-KEY': api_key,
                'estabelecimentoId': estabelecimento_id,
                'Content-Type': 'application/json'
            }
            
            # Fazer requisi√ß√£o
            import requests
            response = requests.get(
                f"{base_url}{endpoint}",
                params=params,
                headers=headers,
                timeout=10
            )
            
            if response.status_code == 200:
                return response.json()
            else:
                logger.error(f"Erro na API Trinks: {response.status_code}")
                return {"error": f"HTTP {response.status_code}"}
                
        except Exception as e:
            logger.error(f"Erro ao chamar API Trinks: {e}")
            return {"error": str(e)}
    
    def _find_professional_match(self, nome_procurado: str, profissionais: List[Dict], estrategias: List[str]) -> Dict[str, Any]:
        """Usa LLM para fazer match inteligente entre nome procurado e lista de profissionais"""
        try:
            logger.info(f"ü§ñ LLM fazendo match inteligente para '{nome_procurado}' entre {len(profissionais)} profissionais")
            
            # Preparar prompt para o LLM
            system_prompt = f"""Voc√™ √© um assistente especializado em identificar profissionais de sa√∫de.

TAREFA: Identificar qual profissional da lista corresponde ao nome mencionado pelo usu√°rio.

NOME PROCURADO: "{nome_procurado}"

LISTA DE PROFISSIONAIS:
{json.dumps(profissionais, indent=2, ensure_ascii=False)}

INSTRU√á√ïES:
1. Analise o nome procurado e compare com a lista de profissionais
2. Considere varia√ß√µes de nomes, apelidos e t√≠tulos
3. Retorne o profissional com maior confian√ßa de match
4. Se houver ambiguidade, escolha o mais prov√°vel

FORMATO DE RESPOSTA (JSON):
{{
    "id": "ID do profissional",
    "nome": "Nome completo do profissional",
    "confianca": "ALTA|MEDIA|BAIXA",
    "razao": "Explica√ß√£o do match"
}}

RESPONDA APENAS em JSON v√°lido."""
            
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=f"Identifique o profissional '{nome_procurado}' na lista fornecida.")
            ]
            
            response = self.llm.invoke(messages)
            logger.info(f"Resposta do LLM para match: {response.content}")
            
            # Limpar e parsear resposta
            content = response.content.strip()
            if content.startswith('```json'):
                content = content[7:-3]  # Remove ```json e ```
            elif content.startswith('```'):
                content = content[3:-3]  # Remove ``` gen√©rico
            
            content = content.strip()
            logger.info(f"Conte√∫do limpo para parse: {content}")
            
            try:
                match_result = json.loads(content)
                
                # Buscar o profissional completo na lista original
                profissional_id = match_result.get('id')
                for prof in profissionais:
                    if str(prof.get('id')) == str(profissional_id):
                        logger.info(f"LLM encontrou profissional: {prof['nome']} (confian√ßa: {match_result.get('confianca', 'N/A')})")
                        logger.info(f"Raz√£o do match: {match_result.get('razao', 'N/A')}")
                        return prof
                
                logger.error(f"ID retornado pelo LLM n√£o encontrado na lista: {profissional_id}")
                return None
                
            except json.JSONDecodeError as e:
                logger.error(f"Erro ao parsear resposta do LLM: {e}")
                logger.error(f"Resposta recebida: {response.content}")
                return None
            
        except Exception as e:
            logger.error(f"Erro no match inteligente com LLM: {e}")
            return None
    
    # NOVOS M√âTODOS PARA FLUXO DE PROCEDIMENTO
    
    def _get_professionals_list(self) -> List[Dict[str, Any]]:
        """Busca lista de profissionais via API Trinks"""
        try:
            result = self._call_trinks_api("/profissionais", {})
            if result and not result.get('error'):
                return result.get('data', [])
            return []
        except Exception as e:
            logger.error(f"Erro ao buscar profissionais: {e}")
            return []
    
    def _get_services_list(self) -> List[Dict[str, Any]]:
        """Busca lista de servi√ßos via API Trinks com filtro de visibilidade"""
        try:
            logger.info("üîç Buscando TODOS os servi√ßos da API Trinks (pageSize=300 + filtro cliente)...")
            
            # Par√¢metros simples: uma chamada com pageSize grande
            params = {
                'page': 1,
                'pageSize': 300,  # Buscar 300 servi√ßos de uma vez
                'somenteVisiveisCliente': True  # Apenas servi√ßos vis√≠veis para cliente
            }
            
            result = self._call_trinks_api("/servicos", params)
            
            if result and not result.get('error'):
                servicos = result.get('data', [])
                logger.info(f"‚úÖ API Trinks retornou {len(servicos)} servi√ßos")
                
                # Log resumido dos servi√ßos
                if servicos:
                    categorias = set(serv.get('categoria', 'Sem categoria') for serv in servicos)
                    logger.info(f"üìã API retornou {len(servicos)} servi√ßos em {len(categorias)} categorias")
                    logger.debug(f"Categorias: {sorted(list(categorias))}")
                    logger.debug(f"Lista completa: {[s.get('nome', 'N/A') for s in servicos]}")
                
                return servicos
            else:
                logger.error(f"‚ùå Erro na API Trinks: {result}")
            return []
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao buscar servi√ßos: {e}")
            return []
    
    def _get_professional_availability(self, profissional_id: str, data: str) -> Dict[str, Any]:
        """Busca disponibilidade de um profissional em uma data espec√≠fica"""
        try:
            logger.info(f"Buscando disponibilidade para profissional ID {profissional_id} na data {data}")
            
            result = self._call_trinks_api(
                f"/agendamentos/profissionais/{data}",
                {'profissionalId': profissional_id}
            )
            
            if result and not result.get('error'):
                # Retornar dados do profissional espec√≠fico
                for prof in result.get('data', []):
                    if str(prof.get('id')) == str(profissional_id):
                        return prof
            return {}
            
        except Exception as e:
            logger.error(f"Erro ao buscar disponibilidade: {e}")
            return {}
    
    def _get_service_availability(self, servico_id: str, data: str, profissional_id: str = None) -> Dict[str, Any]:
        """Busca disponibilidade de um servi√ßo em uma data espec√≠fica, com filtro opcional de profissional"""
        try:
            logger.info(f"Buscando disponibilidade para servi√ßo ID {servico_id} na data {data}" + (f" com filtro de profissional {profissional_id}" if profissional_id else ""))
            
            # Construir endpoint CORRETO conforme documenta√ß√£o Trinks
            endpoint = f"/agendamentos/profissionais/{data}"
            params = {}
            
            # Adicionar par√¢metros conforme documenta√ß√£o
            if servico_id:
                params['servicold'] = servico_id  # ID do servi√ßo
            
            if profissional_id:
                params['profissionalld'] = profissional_id  # ID do profissional
            
            logger.debug(f"Endpoint={endpoint}, Params={params}")
            result = self._call_trinks_api(endpoint, params)
            
            if result and not result.get('error'):
                # Processar dados da API para extrair disponibilidade
                logger.debug(f"Dados brutos da API: {result}")
                
                # Extrair dados do profissional espec√≠fico se filtrado
                if profissional_id:
                    for prof in result.get('data', []):
                        if str(prof.get('id')) == str(profissional_id):
                            logger.debug(f"Profissional encontrado: {prof}")
                            return {
                                'horariosVagos': prof.get('horariosVagos', []),
                                'intervalosVagos': prof.get('intervalosVagos', []),
                                'profissional': prof
                            }
                
                # Se n√£o filtrado por profissional, retornar todos
                logger.debug(f"Retornando dados para todos os profissionais")
                return {
                    'horariosVagos': result.get('data', []),
                    'intervalosVagos': [],
                    'profissionais': result.get('data', [])
                }
            
            logger.warning(f"API retornou erro ou dados vazios: {result}")
            return {}
            
        except Exception as e:
            logger.error(f"Erro ao buscar disponibilidade do servi√ßo: {e}")
            return {}
    
    def _find_service_match(self, nome_procurado: str, servicos: List[Dict], estrategias: List[str]) -> Dict[str, Any]:
        """Usa LLM para fazer match inteligente entre nome procurado e lista de servi√ßos"""
        try:
            logger.info(f"ü§ñ LLM fazendo match inteligente de servi√ßo para '{nome_procurado}' entre {len(servicos)} servi√ßos")
            logger.debug(f"Servi√ßos para an√°lise: {[s.get('nome', 'N/A') for s in servicos]}")
            
            # Preparar prompt para o LLM
            system_prompt = f"""Voc√™ √© um assistente especializado em identificar servi√ßos de sa√∫de.

TAREFA: Identificar qual servi√ßo da lista corresponde ao nome mencionado pelo usu√°rio.

NOME PROCURADO: "{nome_procurado}"

LISTA DE SERVI√áOS:
{json.dumps(servicos, indent=2, ensure_ascii=False)}

ESTRAT√âGIA DE MATCH:
1. **Busca por Palavras-Chave**: Procure por servi√ßos que contenham as palavras principais do nome procurado
2. **Correspond√™ncia Parcial**: N√£o exija match exato - procure por correspond√™ncias parciais
3. **Sin√¥nimos**: Considere varia√ß√µes e sin√¥nimos
4. **Categorias**: Procure por servi√ßos da mesma categoria

EXEMPLOS:
- "limpeza de pele" ‚Üí Procure por servi√ßos que contenham "limpeza" E "pele"
- "massagem relaxante" ‚Üí Procure por servi√ßos que contenham "massagem" OU "relaxante"
- "aplica√ß√£o de enzimas" ‚Üí Procure por servi√ßos que contenham "enzimas" OU "aplica√ß√£o"

INSTRU√á√ïES:
1. Analise o nome procurado e identifique palavras-chave principais
2. Procure na lista por servi√ßos que contenham essas palavras-chave
3. Considere correspond√™ncias parciais - n√£o exija match exato
4. Se encontrar m√∫ltiplos matches, escolha o mais relevante
5. SEMPRE tente encontrar um match - nunca retorne null

FORMATO DE RESPOSTA (JSON):
{{
    "id": "ID do servi√ßo",
    "nome": "Nome completo do servi√ßo",
    "confianca": "ALTA|MEDIA|BAIXA",
    "razao": "Explica√ß√£o do match e palavras-chave encontradas"
}}

IMPORTANTE: 
- SEMPRE tente encontrar um match, mesmo que n√£o seja perfeito
- Use correspond√™ncia parcial - n√£o exija match exato
- Se n√£o encontrar match exato, escolha o mais pr√≥ximo
- NUNCA retorne id ou nome como null

RESPONDA APENAS em JSON v√°lido."""
            
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=f"Identifique o servi√ßo '{nome_procurado}' na lista fornecida.")
            ]
            
            response = self.llm.invoke(messages)
            logger.info(f"Resposta do LLM para match de servi√ßo: {response.content}")
            
            # Limpar e parsear resposta
            content = response.content.strip()
            if content.startswith('```json'):
                content = content[7:-3]  # Remove ```json e ```
            elif content.startswith('```'):
                content = content[3:-3]  # Remove ``` gen√©rico
            
            content = content.strip()
            logger.info(f"Conte√∫do limpo para parse: {content}")
            
            match_result = json.loads(content)
            
            # Buscar o servi√ßo completo na lista original
            servico_id = match_result.get('id')
            for serv in servicos:
                if str(serv.get('id')) == str(servico_id):
                    logger.info(f"LLM encontrou servi√ßo: {serv['nome']} (confian√ßa: {match_result.get('confianca', 'N/A')})")
                    logger.info(f"Raz√£o do match: {match_result.get('razao', 'N/A')}")
                    return serv
            
            logger.error(f"ID retornado pelo LLM n√£o encontrado na lista: {servico_id}")
            return None
            
        except json.JSONDecodeError as e:
            logger.error(f"Erro ao parsear resposta do LLM: {e}")
            logger.error(f"Resposta recebida: {response.content}")
            return None
        
        except Exception as e:
            logger.error(f"Erro no match inteligente de servi√ßo: {e}")
            return None
    
    def _get_professionals_by_service(self, servico_id: str) -> List[Dict[str, Any]]:
        """Busca profissionais que fazem um servi√ßo espec√≠fico"""
        try:
            # Por enquanto, retornar todos os profissionais (implementar filtro depois)
            # TODO: Implementar filtro por servi√ßo quando a API Trinks suportar
            return self._get_professionals_list()
        except Exception as e:
            logger.error(f"Erro ao buscar profissionais por servi√ßo: {e}")
            return []
    
    def _generate_professional_preference_question(self, servico: Dict[str, Any], profissionais: List[Dict[str, Any]], data: str, context: Dict[str, Any]) -> str:
        """Gera pergunta para o usu√°rio escolher profissional preferido"""
        try:
            # Usar prompt da empresa para formatar a pergunta
            return self._generate_response_with_company_prompt(
                "perguntar_preferencia_profissional",
                {
                    'servico': servico['nome'],
                    'data': data,
                    'profissionais_disponiveis': len(profissionais),
                    'nomes_profissionais': [p.get('nome', 'N/A') for p in profissionais[:3]]  # Mostrar primeiros 3
                },
                context
            )
            
        except Exception as e:
            logger.error(f"Erro ao gerar pergunta de prefer√™ncia: {e}")
            # Fallback para resposta padr√£o
            return f"Perfeito! Encontrei o servi√ßo '{servico['nome']}' e {len(profissionais)} profissionais dispon√≠veis para {data}. Tem algum profissional espec√≠fico em mente, ou posso mostrar a disponibilidade de todos?" 
    
    def _generate_response_with_company_prompt(self, action_type: str, data: Dict[str, Any], context: Dict[str, Any] = None) -> str:
        """Wrapper que redireciona para _analyze_with_company_llm mantendo compatibilidade"""
        
        # ‚úÖ Adicionar action_type e data ao contexto para a LLM principal
        if context is None:
            context = {}
        
        # ‚úÖ Enriquecer contexto com dados da action
        enriched_context = context.copy()
        enriched_context['action_type'] = action_type
        enriched_context['action_data'] = data
        
        # ‚úÖ Redirecionar para LLM principal que decide tudo
        return self._analyze_with_company_llm(
            f"Processar a√ß√£o: {action_type}",
            enriched_context
        )
    
    # ‚úÖ M√âTODO REMOVIDO: _generate_fallback_response
    # Agora todos os erros s√£o enviados para o LLM da empresa atrav√©s do fluxo normal
    # O prompt da empresa deve ser configurado para responder adequadamente a erros 
    
    # ‚úÖ M√âTODO REMOVIDO: _get_conversation_state nunca foi usado
    
    def _update_conversation_state(self, waid: str, new_data: Dict[str, Any]):
        """Atualiza o estado da conversa com novas informa√ß√µes extra√≠das"""
        state = self._get_conversation_state(waid)
        
        # ‚úÖ PRESERVAR CONTEXTO: S√≥ atualizar campos que foram realmente mencionados
        for key, value in new_data.items():
            if value is not None and value != "" and value != "null":
                # ‚úÖ Atualiza apenas se o valor for v√°lido
                state[key] = value
                logger.info(f"Campo '{key}' atualizado para: {value}")
            else:
                # ‚úÖ Preserva o valor anterior se o campo n√£o foi mencionado
                logger.info(f"Campo '{key}' preservado com valor anterior: {state.get(key, 'N/A')}")
        
        state['last_update'] = datetime.now()
        logger.info(f"Estado da conversa atualizado para waid {waid}: {state}")
    
    def _merge_extracted_with_state(self, waid: str, extracted_data: Dict[str, Any]) -> Dict[str, Any]:
        """Combina dados extra√≠dos com o estado persistente da conversa de forma inteligente"""
        state = self._get_conversation_state(waid)
        merged_data = state.copy()
        
        # ‚úÖ MESCLAGEM INTELIGENTE: Preservar contexto anterior, atualizar apenas o que mudou
        for key, value in extracted_data.items():
            if value is not None and value != "" and value != "null":
                # ‚úÖ Campo foi mencionado na nova mensagem - atualizar
                old_value = merged_data.get(key, 'N/A')
                merged_data[key] = value
                logger.info(f"‚úÖ Campo '{key}' atualizado: '{old_value}' ‚Üí '{value}'")
            else:
                # ‚úÖ Campo n√£o foi mencionado - preservar valor anterior
                preserved_value = merged_data.get(key, 'N/A')
                logger.info(f"üîÑ Campo '{key}' preservado: '{preserved_value}'")
        
        # Remover campos internos do estado
        merged_data.pop('last_update', None)
        
        logger.info(f"üéØ Dados mesclados para waid {waid}: {merged_data}")
        
        # ‚úÖ VALIDA√á√ÉO FINAL: Garantir que campos cr√≠ticos n√£o sejam perdidos
        critical_fields = ['procedimento', 'data', 'profissional']
        for field in critical_fields:
            if field in merged_data and merged_data[field] and field not in extracted_data:
                logger.info(f"üõ°Ô∏è Campo cr√≠tico '{field}' preservado: '{merged_data[field]}'")
            elif field not in merged_data or not merged_data[field]:
                logger.warning(f"‚ö†Ô∏è Campo cr√≠tico '{field}' n√£o encontrado no estado final")
        
        return merged_data
    
    def _detectar_preferencia_profissional(self, mensagem: str) -> Dict[str, Any]:
        """Detecta se o usu√°rio tem prefer√™ncia por profissional ou √© indiferente"""
        try:
            prompt = f"""
            Analise a seguinte mensagem do usu√°rio e determine se ele est√° indicando que N√ÉO tem prefer√™ncia por profissional espec√≠fico.

            Mensagem: "{mensagem}"

            Responda apenas com um JSON v√°lido:
            {{
                "tem_preferencia": true/false,
                "profissional_especifico": "nome_do_profissional" ou null,
                "razao": "explicacao_curta"
            }}

            Exemplos de "SEM prefer√™ncia":
            - "tanto faz", "qualquer um", "n√£o tenho prefer√™ncia"
            - "pode ser qualquer um", "indiferente", "n√£o importa"
            - "o que tiver dispon√≠vel", "o melhor hor√°rio"

            Exemplos de "COM prefer√™ncia":
            - "com a Dr. Maria", "quero o Jo√£o", "prefiro a Ana"
            - "gostaria da Dra. Silva", "pode ser o Dr. Carlos"
            """
            
            messages = [
                SystemMessage(content=prompt),
                HumanMessage(content=mensagem)
            ]
            
            response = self.llm.invoke(messages)
            content = response.content.strip()
            
            # Limpar resposta do LLM
            if content.startswith('```json'):
                content = content[7:-3]
            elif content.startswith('```'):
                content = content[3:-3]
            
            content = content.strip()
            logger.info(f"Resposta do LLM para prefer√™ncia: {content}")
            
            # Parsear JSON
            try:
                result = json.loads(content)
                logger.info(f"Prefer√™ncia detectada: {result}")
                return result
            except json.JSONDecodeError as e:
                logger.error(f"Erro ao parsear JSON da prefer√™ncia: {e}")
                return {"tem_preferencia": True, "profissional_especifico": None, "razao": "Erro no parse"}
                
        except Exception as e:
            logger.error(f"Erro ao detectar prefer√™ncia de profissional: {e}")
            return {"tem_preferencia": True, "profissional_especifico": None, "razao": "Erro na detec√ß√£o"} 

    def _check_availability_for_all_professionals(self, servico: Dict[str, Any], data: str, context: Dict[str, Any]) -> str:
        """Verifica disponibilidade de TODOS os profissionais para um servi√ßo e data - ABORDAGEM H√çBRIDA"""
        try:
            logger.info(f"üîç ABORDAGEM H√çBRIDA: Verificando disponibilidade de TODOS os profissionais para {servico['nome']} em {data}")
            
            # Buscar disponibilidade de todos os profissionais
            disponibilidade_total = []
            profissionais_com_horarios = []
            
            # Buscar lista de profissionais que fazem o servi√ßo
            profissionais = self._get_professionals_list()
            logger.info(f"üìã Analisando {len(profissionais)} profissionais para o servi√ßo")
            
            for prof in profissionais:
                # Buscar disponibilidade espec√≠fica para este profissional + servi√ßo + data
                disponibilidade = self._get_service_availability(servico['id'], data, prof['id'])
                
                if disponibilidade and disponibilidade.get('available_slots'):
                    # Obter dura√ß√£o do procedimento para valida√ß√£o
                    procedure_duration = self.trinks_rules.get_procedure_duration(
                        servico['nome'], 
                        servico
                    )
                    
                    # Validar slots por dura√ß√£o
                    available_slots = disponibilidade.get('available_slots', [])
                    if available_slots:
                        slots_data = [{'horario': slot, 'disponivel': True} for slot in available_slots]
                        valid_slots = self.trinks_rules.filter_available_slots_by_duration(
                            slots_data, 
                            procedure_duration
                        )
                        
                        if valid_slots:
                            valid_horarios = [slot['horario_inicio'] for slot in valid_slots]
                            profissionais_com_horarios.append({
                                'profissional': prof,
                                'horarios': valid_horarios,
                                'quantidade_horarios': len(valid_horarios),
                                'disponibilidade_bruta': disponibilidade
                            })
                            logger.info(f"‚úÖ {prof['nome']}: {len(valid_horarios)} hor√°rios v√°lidos")
                        else:
                            logger.info(f"‚ùå {prof['nome']}: hor√°rios n√£o atendem dura√ß√£o do procedimento")
                    else:
                        logger.info(f"‚ùå {prof['nome']}: sem hor√°rios dispon√≠veis")
                else:
                    logger.info(f"‚ùå {prof['nome']}: sem disponibilidade para este servi√ßo/data")
            
            if not profissionais_com_horarios:
                return self._generate_response_with_company_prompt(
                    "verificar_disponibilidade",
                    {
                        'error': f"N√£o h√° hor√°rios dispon√≠veis para {servico['nome']} em {data}",
                        'suggestion': "Gostaria de verificar outra data?",
                        'context': context
                    },
                    context
                )
            
            # ‚úÖ PRIORIZAR por quantidade de hor√°rios (mais hor√°rios primeiro)
            profissionais_com_horarios.sort(key=lambda x: x['quantidade_horarios'], reverse=True)
            
            logger.info(f"üéØ Profissionais ordenados por prioridade (mais hor√°rios primeiro):")
            for i, prof in enumerate(profissionais_com_horarios):
                logger.info(f"   {i+1}. {prof['profissional']['nome']}: {prof['quantidade_horarios']} hor√°rios")
            
            # Retornar disponibilidade priorizada de todos os profissionais
            return self._generate_response_with_company_prompt(
                "verificar_disponibilidade",
                {
                    'servico': servico,
                    'data': data,
                    'disponibilidade': profissionais_com_horarios,
                    'tipo': 'todos_profissionais_priorizados',
                    'context': context
                },
                context
            )
            
        except Exception as e:
            logger.error(f"Erro ao verificar disponibilidade de todos os profissionais: {e}")
            return self._generate_response_with_company_prompt(
                "verificar_disponibilidade",
                {
                    'error': f"Erro ao verificar disponibilidade: {str(e)}",
                    'context': context
                },
                context
            )
    
    def _check_availability_for_specific_professional(self, servico: Dict[str, Any], profissional_nome: str, data: str, context: Dict[str, Any]) -> str:
        """Verifica disponibilidade de um profissional espec√≠fico para um servi√ßo e data"""
        try:
            logger.info(f"Verificando disponibilidade de {profissional_nome} para {servico['nome']} em {data}")
            
            # Buscar lista de profissionais para fazer match
            profissionais = self._get_professionals_list()
            profissional = self._find_professional_match(profissional_nome, profissionais, [])
            
            if not profissional:
                return self._generate_response_with_company_prompt(
                    "verificar_disponibilidade",
                    {
                        'error': f"N√£o consegui identificar o profissional '{profissional_nome}'",
                        'suggestion': "Pode ser mais espec√≠fico?",
                        'context': context
                    },
                    context
                )
            
            # Verificar disponibilidade do profissional espec√≠fico
            disponibilidade = self._get_professional_availability(profissional['id'], data)
            
            if not disponibilidade or not disponibilidade.get('horarios_disponiveis'):
                return self._generate_response_with_company_prompt(
                    "verificar_disponibilidade",
                    {
                        'error': f"{profissional['nome']} n√£o tem hor√°rios dispon√≠veis para {servico['nome']} em {data}",
                        'suggestion': "Gostaria de verificar outra data ou outro profissional?",
                        'context': context
                    },
                    context
                )
            
            # Retornar disponibilidade do profissional espec√≠fico
            return self._generate_response_with_company_prompt(
                "verificar_disponibilidade",
                {
                    'servico': servico,
                    'profissional': profissional,
                    'data': data,
                    'disponibilidade': disponibilidade.get('horarios_disponiveis', []),
                    'tipo': 'profissional_especifico',
                    'context': context
                },
                context
            )
            
        except Exception as e:
            logger.error(f"Erro ao verificar disponibilidade de profissional espec√≠fico: {e}")
            return self._generate_response_with_company_prompt(
                "verificar_disponibilidade",
                {
                    'error': f"Erro ao verificar disponibilidade: {str(e)}",
                    'context': context
                },
                context
            )
    
    def _generate_generic_preference_question(self, servico: Dict[str, Any], data: str, context: Dict[str, Any]) -> str:
        """Gera pergunta gen√©rica sobre prefer√™ncia de profissional SEM sugerir nomes"""
        try:
            return self._generate_response_with_company_prompt(
                "verificar_disponibilidade",
                {
                    'servico': servico,
                    'data': data,
                    'pergunta': 'preferencia_generica',
                    'context': context
                },
                context
            )
        except Exception as e:
            logger.error(f"Erro ao gerar pergunta de prefer√™ncia gen√©rica: {e}")
            return "Gostaria de verificar a disponibilidade de todos os profissionais ou tem alguma prefer√™ncia espec√≠fica?" 
    
    def _execute_single_action(self, action: str, extracted_data: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
        """‚úÖ NOVA FUN√á√ÉO: Executa uma action individual e retorna resultado estruturado"""
        try:
            # Executar a action via Rules
            step_result = self.trinks_rules.execute_step(action, extracted_data, self.empresa_config, context)
            logger.info(f"üîß Resultado da execu√ß√£o: {step_result}")
            
            # ‚úÖ NOVO: Seguir instru√ß√µes de cache das Rules
            if step_result.get('cache_instructions'):
                logger.info(f"üìã Seguindo instru√ß√µes de cache: {step_result.get('cache_instructions')}")
                self._update_cache_from_instructions(step_result.get('cache_instructions'), extracted_data)
            
            # Retornar resultado estruturado para an√°lise posterior
            return {
                "status": "action_executada",
                "action": action,
                "result": step_result
            }
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao executar {action}: {e}")
            return {
                "status": "erro",
                "action": action,
                "error": str(e)
            }
    
    def _execute_multiple_actions(self, actions: list, extracted_data: Dict[str, Any], next_steps: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
        """‚úÖ NOVA FUN√á√ÉO: Executa m√∫ltiplas actions em sequ√™ncia e retorna resultados estruturados"""
        try:
            logger.info(f"üîÑ Executando {len(actions)} actions em sequ√™ncia: {actions}")
            
            results = {}
            for i, action in enumerate(actions):
                logger.info(f"üîÑ Executando action {i+1}/{len(actions)}: {action}")
                
                # Executar action individual
                step_result = self.trinks_rules.execute_step(action, extracted_data, self.empresa_config, context)
                logger.info(f"üîß Resultado da execu√ß√£o {action}: {step_result}")
                
                # ‚úÖ NOVO: Seguir instru√ß√µes de cache das Rules
                if step_result.get('cache_instructions'):
                    logger.info(f"üìã Seguindo instru√ß√µes de cache para {action}: {step_result.get('cache_instructions')}")
                    self._update_cache_from_instructions(step_result.get('cache_instructions'), extracted_data)
                
                # Armazenar resultado estruturado
                results[action] = step_result
                
                # Se falhou, parar execu√ß√£o
                if step_result.get('status') == 'erro':
                    logger.error(f"‚ùå Action {action} falhou, parando execu√ß√£o")
                    break
            
            # Retornar resultados estruturados para an√°lise posterior
            return {
                "status": "actions_executadas",
                "results": results,
                "actions_executadas": actions
            }
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao executar m√∫ltiplas actions: {e}")
            return {
                "status": "erro",
                "error": str(e),
                "results": {}
            }

    def _handle_ask_user_direct(self, business_rules: list, extracted_data: Dict[str, Any], next_steps: Dict[str, Any], context: Dict[str, Any], intent: str) -> str:
        """‚úÖ NOVA FUN√á√ÉO: ask_user vai DIRETO para o prompt da empresa (sem LLM intermedi√°ria)"""
        logger.info("üë§ ask_user - indo DIRETO para o prompt da empresa")
        
        # ‚úÖ Preparar dados para o prompt da empresa
        ask_user_data = {
            'action': 'ask_user',
            'missing_data': next_steps.get('missing_data', []),
            'business_rules': business_rules,
            'extracted_data': extracted_data,
            'context': context
        }
        
        # ‚úÖ Gerar resposta formatada DIRETAMENTE pelo prompt da empresa
        formatted_response = self._generate_response_with_company_prompt(
            intent,
            ask_user_data,
            context
        )
        logger.info(f"üë§ Resposta formatada DIRETA pela empresa: {formatted_response}")
        
        # ‚úÖ Retornar string pronta para o usu√°rio
        return formatted_response

    def _format_company_knowledge(self) -> str:
        """Formata as knowledge da empresa para uso no prompt"""
        try:
            knowledge = self.empresa_config.get('knowledge_json', {})
            items = knowledge.get('items', [])
            
            if not items:
                return "Nenhuma informa√ß√£o espec√≠fica configurada."
            
            formatted = []
            for item in items:
                if isinstance(item, dict):
                    key = item.get('key', '')
                    description = item.get('description', '')
                    if key and description:
                        formatted.append(f"‚Ä¢ {key}: {description}")
            
            return "\n".join(formatted) if formatted else "Nenhuma informa√ß√£o espec√≠fica configurada."
        except Exception as e:
            logger.error(f"Erro ao formatar knowledge: {e}")
            return "Erro ao carregar informa√ß√µes da empresa"

    def _format_conversation_history(self, messages: List) -> str:
        """Formata hist√≥rico da conversa para o prompt"""
        if not messages:
            return "Nenhum hist√≥rico dispon√≠vel"
        
        formatted = []
        for msg in messages:
            if hasattr(msg, 'content'):
                role = "Cliente" if hasattr(msg, '__class__') and 'Human' in msg.__class__.__name__ else "Assistente"
                formatted.append(f"‚Ä¢ {role}: {msg.content}")
        
        return "\n".join(formatted)

    def _analyze_with_company_llm(self, message: str, context: Dict) -> str:
        """LLM da empresa analisa TUDO e decide o caminho"""
        
        # ‚úÖ OBTER hist√≥rico da mem√≥ria LangChain
        conversation_history = []
        if self.memory.chat_memory.messages:
            conversation_history = self.memory.chat_memory.messages[-6:]
        
        # ‚úÖ OBTER regras de neg√≥cio do contexto
        business_rules = context.get('business_rules', [])
        
        # ‚úÖ OBTER dados extra√≠dos do contexto
        extracted_data = context.get('extracted_data', {})
        
        # ‚úÖ OBTER action_type e dados das tools (unificando results e action_data)
        action_type = context.get('action_type', 'an√°lise_geral')
        results = context.get('results', {})
        action_data = context.get('action_data', {})
        
        # ‚úÖ COMBINAR para contemplar ambos os casos de uso
        tools_data = results if results else action_data
        
        system_prompt = f"""Voc√™ √© um assistente virtual da {self.empresa_config.get('nome', 'Empresa')}.

PROMPT DA EMPRESA:
{self.empresa_config.get('prompt', '')}

KNOWLEDGE DA EMPRESA:
{self._format_company_knowledge()}

HIST√ìRICO DA CONVERSA (√∫ltimas 6 mensagens):
{self._format_conversation_history(conversation_history)}

REGRAS DE NEG√ìCIO:
{business_rules if business_rules else 'Nenhuma regra espec√≠fica definida'}

DADOS EXTRA√çDOS:
{json.dumps(extracted_data, indent=2, ensure_ascii=False, default=str) if extracted_data else 'Nenhum dado extra√≠do'}

TIPO DE A√á√ÉO:
{action_type}

DADOS DA A√á√ÉO:
{json.dumps(tools_data, indent=2, ensure_ascii=False, default=str) if tools_data else 'Nenhum dado de a√ß√£o'}

INSTRU√á√ïES:
Analise a mensagem do usu√°rio e responda de acordo com o prompt da empresa, considerando o contexto da conversa e as regras de neg√≥cio.

IMPORTANTE - M√öLTIPLAS MENSAGENS:
Se voc√™ receber m√∫ltiplas mensagens (como agora), N√ÉO responda cada uma separadamente.
Analise tudo junto e d√™ UMA resposta inteligente que aborde o contexto completo.

EXEMPLO: Se o usu√°rio disser 'Oi' + 'Tudo bem?', responda 'Oi! Tudo bem sim, obrigado! üòä Como posso te ajudar hoje?'"""

        # ‚úÖ UMA CHAMADA LLM que decide tudo
        response = self.llm.invoke([
            SystemMessage(content=system_prompt),
            HumanMessage(content=message)
        ])
        
        return response.content.strip()

    def _call_complete_flow(self, message: str, waid: str, context: Dict) -> str:
        """Chama o fluxo completo baseado na API ativa da empresa"""
        
        # ‚úÖ DETECTAR qual API est√° ativa e chamar fluxo apropriado
        active_apis = []
        
        if self.empresa_config.get('trinks_enabled'):
            active_apis.append('trinks')
        
        if self.empresa_config.get('google_calendar_enabled'):
            active_apis.append('google_calendar')
        
        if self.empresa_config.get('google_sheets_enabled'):
            active_apis.append('google_sheets')
        
        logger.info(f"üîÑ APIs ativas detectadas: {active_apis}")
        
        # ‚úÖ DECIDIR qual fluxo usar baseado na API ativa
        if 'trinks' in active_apis:
            logger.info("üîÑ Usando fluxo Trinks")
            return self._call_trinks_flow(message, waid, context)
        
        elif 'google_calendar' in active_apis:
            logger.info("üîÑ Usando fluxo Google Calendar")
            return self._call_google_calendar_flow(message, waid, context)
        
        elif 'google_sheets' in active_apis:
            logger.info("üîÑ Usando fluxo Google Sheets")
            return self._call_google_sheets_flow(message, waid, context)
        
        else:
            logger.warning("‚ö†Ô∏è Nenhuma API ativa detectada")
            return self._generate_response_with_company_prompt(
                "erro_sistema",
                {'error': "Nenhuma API ativa detectada", 'context': context},
                context
            )

    def analyze_and_respond(self, message: str, waid: str, context: Dict[str, Any] = None) -> str:
        """M√©todo principal que analisa e decide o caminho"""
        try:
            logger.info(f"Analisando mensagem para waid {waid}")
            
            # ‚úÖ CARREGAR contexto do cache por waid
            self._load_conversation_context(waid)
            
            # ‚úÖ PRIMEIRO: An√°lise inteligente com LLM da empresa
            response = self._analyze_with_company_llm(message, context)
            
            # ‚úÖ SEGUNDO: Se LLM disse que vai processar ‚Üí chama fluxo completo
            if "vou processar" in response.lower() or "processar" in response.lower():
                logger.info("üîÑ LLM decidiu usar fluxo completo - chamando TrinksRules")
                return self._call_complete_flow(message, waid, context)
            
            # ‚úÖ TERCEIRO: Resposta direta da empresa
            logger.info("‚úÖ Resposta direta da empresa")
            
            # ‚úÖ CR√çTICO: SALVAR mensagem e resposta na mem√≥ria ANTES de retornar
            self.memory.chat_memory.add_user_message(message)
            self.memory.chat_memory.add_ai_message(response)
            
            # ‚úÖ SALVAR contexto no cache para manter hist√≥rico
            self._save_conversation_context(waid, {})
            
            return response
            
        except Exception as e:
            logger.error(f"Erro na an√°lise: {e}")
            return "Ocorreu um erro. Tente novamente."

    def _call_trinks_flow(self, message: str, waid: str, context: Dict) -> str:
        """Chama fluxo Trinks (process_message atual)"""
        return self.process_message(message, waid, context)

    def _call_google_calendar_flow(self, message: str, waid: str, context: Dict) -> str:
        """Chama fluxo Google Calendar (quando implementado)"""
        # TODO: Implementar fluxo Google Calendar
        return "Funcionalidade Google Calendar em desenvolvimento"

    def _call_google_sheets_flow(self, message: str, waid: str, context: Dict) -> str:
        """Chama fluxo Google Sheets (quando implementado)"""
        # TODO: Implementar fluxo Google Sheets
        return "Funcionalidade Google Sheets em desenvolvimento"