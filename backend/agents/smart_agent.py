from typing import Dict, Any, List
from langchain_openai import ChatOpenAI
from langchain.memory import ConversationBufferWindowMemory
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langchain_core.tools import tool as lc_tool
import logging
import json
import requests
from datetime import datetime

from .api_rules_engine import api_rules_engine

logger = logging.getLogger(__name__)

class SmartAgent:
    """Agente inteligente que usa LLM para identificar inten√ß√µes e API Rules para executar fluxos"""
    
    def __init__(self, empresa_config: Dict[str, Any]):
        self.empresa_config = empresa_config
        
        # LLM para identifica√ß√£o inteligente de inten√ß√µes
        self.llm = ChatOpenAI(
            api_key=empresa_config.get('openai_key'),
            temperature=0.1,
            model="gpt-4o"
        )
        
        # Memory para contexto da conversa
        self.memory = ConversationBufferWindowMemory(
            k=20,
            return_messages=True
        )
        
        # Tools estruturadas
        self.tools = self._setup_tools()
        
        # Contexto da conversa atual
        self.current_conversation_state = None
        
        # Cache global de contextos por waid (WhatsApp ID)
        if not hasattr(SmartAgent, '_conversation_cache'):
            SmartAgent._conversation_cache = {}
    
    def _setup_tools(self) -> List:
        """Configura as tools dispon√≠veis"""
        tools = []
        
        @lc_tool("get_business_knowledge")
        def get_business_knowledge(key: str) -> str:
            """Consulta informa√ß√µes espec√≠ficas da empresa (hor√°rios, regras, promo√ß√µes, etc.)"""
            try:
                knowledge = self.empresa_config.get('knowledge_json', {})
                items = knowledge.get('items', [])
                
                key_lower = key.lower().strip()
                for item in items:
                    if isinstance(item, dict):
                        item_key = item.get('key', '').lower().strip()
                        if item_key == key_lower:
                            return item.get('content', 'Informa√ß√£o n√£o encontrada')
                
                return f"Informa√ß√£o sobre '{key}' n√£o encontrada. Tente: hor√°rios, regras, promo√ß√µes, endere√ßo, telefone."
            except Exception as e:
                logger.error(f"Erro ao buscar conhecimento: {e}")
                return "Erro ao buscar informa√ß√µes da empresa"
        
        @lc_tool("get_api_rules")
        def get_api_rules() -> str:
            """Retorna as regras da API ativa para a empresa"""
            try:
                rules = api_rules_engine.get_api_rules(self.empresa_config)
                return f"Regras da API {rules['api_name']}: Email obrigat√≥rio: {rules['email_required']}, WaId obrigat√≥rio: {rules['waid_required']}"
            except Exception as e:
                logger.error(f"Erro ao buscar regras da API: {e}")
                return "Erro ao buscar regras da API"
        
        @lc_tool("get_available_flows")
        def get_available_flows() -> str:
            """Retorna os fluxos dispon√≠veis para a API ativa"""
            try:
                rules = api_rules_engine.get_api_rules(self.empresa_config)
                flows = rules.get('fluxos_por_intencao', {})
                
                if flows:
                    flow_list = []
                    for intent, flow in flows.items():
                        flow_list.append(f"- {intent}: {flow['descricao']}")
                    
                    return f"Fluxos dispon√≠veis para {rules['api_name']}:\n" + "\n".join(flow_list)
                else:
                    return f"Nenhum fluxo configurado para {rules['api_name']}"
            except Exception as e:
                logger.error(f"Erro ao buscar fluxos: {e}")
                return "Erro ao buscar fluxos dispon√≠veis"
        
        @lc_tool("execute_flow")
        def execute_flow(intent: str, **kwargs) -> str:
            """Executa um fluxo espec√≠fico baseado na inten√ß√£o"""
            try:
                rules = api_rules_engine.get_api_rules(self.empresa_config)
                flows = rules.get('fluxos_por_intencao', {})
                
                if intent not in flows:
                    return f"Inten√ß√£o '{intent}' n√£o suportada. Fluxos dispon√≠veis: {list(flows.keys())}"
                
                flow = flows[intent]
                required_fields = flow.get('campos_obrigatorios', [])
                
                # Verificar campos obrigat√≥rios
                missing_fields = []
                for field in required_fields:
                    if field not in kwargs:
                        missing_fields.append(field)
                
                if missing_fields:
                    return f"Campos obrigat√≥rios faltando para '{intent}': {missing_fields}"
                
                # Simular execu√ß√£o do fluxo
                steps = flow.get('passos', [])
                result = f"Executando fluxo '{intent}':\n"
                
                for step in steps:
                    result += f"‚úÖ {step}\n"
                
                result += f"\nDados recebidos: {kwargs}"
                return result
                
            except Exception as e:
                logger.error(f"Erro ao executar fluxo: {e}")
                return f"Erro ao executar fluxo '{intent}': {str(e)}"
        
        tools.extend([
            get_business_knowledge,
            get_api_rules,
            get_available_flows,
            execute_flow
        ])
        
        return tools
    
    def process_message(self, message: str, context: Dict[str, Any] = None) -> str:
        """Processa uma mensagem usando LLM para identificar inten√ß√£o e executar fluxo"""
        try:
            # 0. Carregar contexto da conversa se dispon√≠vel
            waid = context.get('waid') if context else None
            if waid:
                self._load_conversation_context(waid)
                logger.info(f"Contexto carregado para waid {waid}, mensagens na mem√≥ria: {len(self.memory.chat_memory.messages)}")
            
            # 1. Usar LLM para identificar inten√ß√£o
            intent = self._detect_intent_with_llm(message, context)
            logger.info(f"Inten√ß√£o detectada: {intent}")
            
            # 2. Verificar se a inten√ß√£o √© suportada pela API
            if intent and intent != "general":
                # 3. Executar fluxo correspondente
                response = self._execute_intent_flow(intent, message, context)
            else:
                # 4. Gerar resposta geral
                response = self._generate_general_response(message, context)
            
            # 5. Salvar no memory local
            logger.info(f"Salvando contexto local: input='{message}', output='{response[:100]}...'")
            self.memory.save_context(
                {"input": message},
                {"output": response}
            )
            logger.info(f"Contexto local salvo! Total de mensagens na mem√≥ria: {len(self.memory.chat_memory.messages)}")
            
            # 6. Salvar no cache global se tiver waid
            if waid:
                self._save_conversation_context(waid)
            
            return response
            
        except Exception as e:
            logger.error(f"Erro ao processar mensagem: {e}")
            return f"Desculpe, tive um problema t√©cnico: {str(e)}"
    
    def _detect_intent_with_llm(self, message: str, context: Dict[str, Any] = None) -> str:
        """Usa LLM para identificar a inten√ß√£o da mensagem com contexto da conversa"""
        try:
            # Obter fluxos dispon√≠veis
            rules = api_rules_engine.get_api_rules(self.empresa_config)
            flows = rules.get('fluxos_por_intencao', {})
            available_intents = list(flows.keys()) if flows else []
            
            # Prompt para o LLM
            system_prompt = f"""Voc√™ √© um assistente especializado em identificar inten√ß√µes de clientes.

INTEN√á√ïES SUPORTADAS (se configuradas):
{', '.join(available_intents) if available_intents else 'Nenhuma inten√ß√£o espec√≠fica configurada'}

INSTRU√á√ïES CR√çTICAS:
- Analise a mensagem do cliente
- SEMPRE considere o contexto da conversa anterior
- Se houver fluxos configurados, identifique a inten√ß√£o
- Se n√£o houver fluxos, responda "general"
- Responda APENAS com o nome da inten√ß√£o ou "general"

REGRA DE CLASSIFICA√á√ÉO FUNDAMENTAL:
- agendar_consulta: S√ì quando o cliente j√° confirmou alguma das sugest√µes de hor√°rio que enviamos
- verificar_disponibilidade: Para TODAS as outras situa√ß√µes

EXEMPLOS DE CLASSIFICA√á√ÉO:
- "Queria fazer aplica√ß√£o de enzimas" ‚Üí verificar_disponibilidade
- "A Dra. X tem hor√°rio dia 24?" ‚Üí verificar_disponibilidade  
- "Queria agendar com Dr. Jo√£o amanh√£" ‚Üí verificar_disponibilidade
- "Sim, esse hor√°rio de amanh√£ √†s 14h est√° perfeito!" ‚Üí agendar_consulta
- "Perfeito, confirma o dia 25 √†s 15h" ‚Üí agendar_consulta
- "Isso mesmo, agenda para quinta √†s 10h" ‚Üí agendar_consulta

REGRAS DE CONTEXTO:
1. Se o usu√°rio fizer uma pergunta de follow-up (ex: "E para dia 26?"), mantenha a inten√ß√£o da conversa anterior
2. Se o usu√°rio mencionar apenas uma nova data/hor√°rio, mantenha a inten√ß√£o de verificar_disponibilidade
3. Use o hist√≥rico da conversa para entender o que o usu√°rio quer
4. SEMPRE priorize verificar_disponibilidade, a menos que seja uma confirma√ß√£o expl√≠cita de hor√°rio sugerido"""

            # Mensagens para o LLM
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=message)
            ]
            
            # Adicionar contexto da conversa se dispon√≠vel
            if self.memory.chat_memory.messages:
                # Usar at√© 10 mensagens para melhor contexto
                context_messages = self.memory.chat_memory.messages[-10:]
                logger.info(f"Adicionando contexto da conversa: {len(context_messages)} mensagens anteriores")
                logger.info(f"√öltimas mensagens do contexto: {[msg.content for msg in context_messages[-4:]]}")
                messages.extend(context_messages)
            else:
                logger.warning("NENHUM contexto dispon√≠vel para detec√ß√£o de inten√ß√£o!")
            
            # Gerar resposta
            response = self.llm.invoke(messages)
            intent = response.content.strip().lower()
            
            # Validar se a inten√ß√£o √© v√°lida
            if intent in available_intents or intent == "general":
                return intent
            else:
                logger.warning(f"Inten√ß√£o inv√°lida retornada pelo LLM: {intent}")
                return "general"
                
        except Exception as e:
            logger.error(f"Erro ao detectar inten√ß√£o com LLM: {e}")
            return "general"
    
    def _execute_intent_flow(self, intent: str, message: str, context: Dict[str, Any] = None) -> str:
        """Executa o fluxo correspondente √† inten√ß√£o"""
        try:
            # Obter waid do contexto
            waid = context.get('waid') if context else None
            if not waid:
                logger.warning("Waid n√£o encontrado no contexto, usando estado padr√£o")
                waid = "default"
            
            # 1. Extrair informa√ß√µes da mensagem
            extracted_data = self._extract_information(message)
            logger.info(f"Dados extra√≠dos da mensagem: {extracted_data}")
            
            # 2. Atualizar estado da conversa
            self._update_conversation_state(waid, extracted_data)
            
            # 3. Mesclar dados extra√≠dos com estado persistente
            merged_data = self._merge_extracted_with_state(waid, extracted_data)
            logger.info(f"Dados mesclados com estado: {merged_data}")
            
            # 4. Executar fluxo baseado na inten√ß√£o
            if intent == "verificar_disponibilidade":
                return self._execute_availability_check(merged_data, context)
            elif intent == "agendar_consulta":
                return self._execute_reservation_creation(merged_data, context)
            elif intent == "cancelar_consulta":
                return self._execute_reservation_cancellation(merged_data, context)
            elif intent == "reagendar_consulta":
                return self._execute_reservation_reschedule(merged_data, context)
            else:
                return f"Inten√ß√£o '{intent}' n√£o suportada"
            
        except Exception as e:
            logger.error(f"Erro ao executar fluxo: {e}")
            return f"Erro ao processar sua solicita√ß√£o: {str(e)}"
    
    def _generate_general_response(self, message: str, context: Dict[str, Any] = None) -> str:
        """Gera resposta para mensagens gerais usando prompt da empresa"""
        try:
            # Usar prompt da empresa para resposta geral
            return self._generate_response_with_company_prompt(
                "resposta_geral",
                {'message': message, 'context': context},
                context
            )
            
        except Exception as e:
            logger.error(f"Erro ao gerar resposta geral: {e}")
            return "Ol√°! Como posso ajudar voc√™ hoje?"
    
    def get_conversation_summary(self) -> Dict[str, Any]:
        """Retorna um resumo do estado atual da conversa"""
        return {
            "status": "active",
            "memory_size": len(self.memory.chat_memory.messages),
            "tools_available": len(self.tools),
            "empresa": self.empresa_config.get('nome', 'N/A')
        }
    
    def _load_conversation_context(self, waid: str) -> None:
        """Carrega contexto de conversa do cache global"""
        if waid in SmartAgent._conversation_cache:
            cached_messages = SmartAgent._conversation_cache[waid]
            logger.info(f"Carregando contexto para waid {waid}: {len(cached_messages)} mensagens")
            
            # Restaurar mensagens na mem√≥ria
            for msg in cached_messages:
                if msg.get('type') == 'human':
                    self.memory.chat_memory.add_user_message(msg['content'])
                elif msg.get('type') == 'ai':
                    self.memory.chat_memory.add_ai_message(msg['content'])
        else:
            logger.info(f"Primeira mensagem para waid {waid}, criando novo contexto")
    
    def _save_conversation_context(self, waid: str) -> None:
        """Salva contexto de conversa no cache global"""
        messages = []
        for msg in self.memory.chat_memory.messages:
            if hasattr(msg, 'type') and msg.type == 'human':
                messages.append({'type': 'human', 'content': msg.content})
            elif hasattr(msg, 'type') and msg.type == 'ai':
                messages.append({'type': 'ai', 'content': msg.content})
            else:
                # Fallback para diferentes tipos de mensagem
                messages.append({'type': 'unknown', 'content': str(msg.content)})
        
        SmartAgent._conversation_cache[waid] = messages
        logger.info(f"Contexto salvo para waid {waid}: {len(messages)} mensagens")
    
    def _extract_information(self, message: str) -> Dict[str, Any]:
        """Extrai informa√ß√µes da mensagem usando LLM com contexto da conversa e estado persistente"""
        
        # Obter contexto limitado (√∫ltimas 10 mensagens para melhor contexto)
        context_messages = []
        if self.memory.chat_memory.messages:
            # Usar at√© 10 mensagens para melhor contexto e performance
            context_messages = self.memory.chat_memory.messages[-10:]
            logger.info(f"Adicionando contexto para extra√ß√£o: {len(context_messages)} mensagens anteriores")
            logger.info(f"√öltimas mensagens do contexto: {[msg.content for msg in context_messages[-4:]]}")
        else:
            logger.warning("NENHUM contexto dispon√≠vel para extra√ß√£o!")
        
        # Construir prompt com foco no formato JSON, contexto e prioriza√ß√£o de dados novos
        system_prompt = f"""Voc√™ √© um assistente que extrai informa√ß√µes de conversas de WhatsApp para agendamentos.

CONTEXTO ATUAL: Hoje √© {datetime.now().strftime('%d/%m/%Y')} (DD/MM/YYYY).

FUN√á√ÉO PRINCIPAL: Analisar a conversa e retornar APENAS um objeto JSON com as informa√ß√µes extra√≠das.

CAMPOS PARA EXTRA√á√ÉO:
- profissional: nome da pessoa mencionada (se houver)
- procedimento: tipo de servi√ßo/procedimento (se houver)
- data: data mencionada (converta para YYYY-MM-DD)
- horario: hor√°rio mencionado (se houver)
- servico: tipo de servi√ßo (se houver)
- preferencia_profissional: prefer√™ncia expressa (se houver)

DETEC√á√ÉO AUTOM√ÅTICA DE PREFER√äNCIA:
- Se o usu√°rio disser "tanto faz", "qualquer um", "n√£o tenho prefer√™ncia" ‚Üí profissional: "indiferente"
- Se o usu√°rio disser "pode ser qualquer um", "indiferente" ‚Üí profissional: "indiferente"
- Se o usu√°rio disser "o que tiver dispon√≠vel" ‚Üí profissional: "indiferente"

CONVERS√ÉO DE DATAS:
- "25/08" ‚Üí "2025-08-25"
- "segunda" ‚Üí pr√≥xima segunda-feira em YYYY-MM-DD
- "amanh√£" ‚Üí data de amanh√£ em YYYY-MM-DD
- "hoje" ‚Üí data de hoje em YYYY-MM-DD

REGRAS CR√çTICAS DE PRIORIDADE:
1. SEMPRE retorne APENAS JSON v√°lido
2. A MENSAGEM ATUAL SEMPRE TEM PRIORIDADE sobre o contexto anterior
3. Se a mensagem atual mencionar nova data, use APENAS ela (ignore datas anteriores)
4. Se a mensagem atual mencionar novo hor√°rio, use APENAS ele (ignore hor√°rios anteriores)
5. Se a mensagem atual mencionar novo profissional, use APENAS ele (ignore profissionais anteriores)
6. Use o contexto apenas para informa√ß√µes N√ÉO mencionadas na mensagem atual
7. NUNCA mantenha dados antigos se novos foram explicitamente mencionados

EXEMPLOS DE PRIORIDADE:
- "E para dia 28/08?" ‚Üí {{"data": "2025-08-28"}} (IGNORE data anterior 29/08)
- "E para √†s 15h?" ‚Üí {{"horario": "15:00"}} (IGNORE hor√°rio anterior)
- "E para amanh√£?" ‚Üí {{"data": "2025-08-15"}} (IGNORE data anterior)
- "E para a Maria?" ‚Üí {{"profissional": "maria"}} (IGNORE profissional anterior)

EXEMPLOS DE RESPOSTA:
- "Oi queria marcar retorno com a amabile" ‚Üí {{"profissional": "amabile"}}
- "Para segunda feira" ‚Üí {{"data": "2025-08-18"}}
- "as 19 ela tem?" ‚Üí {{"horario": "19:00", "profissional": "amabile"}}
- "E para dia 29/08?" ‚Üí {{"data": "2025-08-29", "profissional": "amabile"}}
- "Tanto faz, qualquer um" ‚Üí {{"profissional": "indiferente"}}
- "Pode ser qualquer um" ‚Üí {{"profissional": "indiferente"}}

IMPORTANTE: A mensagem atual SEMPRE tem prioridade sobre o contexto anterior. Se o usu√°rio mencionar uma nova data, hor√°rio ou profissional, use APENAS essas informa√ß√µes novas.

FORMATO OBRIGAT√ìRIO: Retorne APENAS o JSON, sem texto adicional, sem explica√ß√µes."""
        
        try:
            messages = [SystemMessage(content=system_prompt)]
            
            # Adicionar contexto da conversa (√∫ltimas 10 mensagens)
            if context_messages:
                messages.extend(context_messages)
            
            # Adicionar a mensagem atual
            messages.append(HumanMessage(content=message))
            
            response = self.llm.invoke(messages)
            
            # LOG da resposta bruta do LLM
            logger.info(f"Resposta bruta do LLM: '{response.content}'")
            logger.info(f"Tamanho da resposta: {len(response.content)}")
            
            # Verificar se a resposta est√° vazia
            if not response.content or response.content.strip() == "":
                logger.error("LLM retornou resposta vazia")
                return {}
            
            # Limpar resposta do LLM (remover backticks se existirem)
            content = response.content.strip()
            if content.startswith('```json'):
                content = content[7:-3]  # Remove ```json e ```
            elif content.startswith('```'):
                content = content[3:-3]  # Remove ``` gen√©rico
            
            content = content.strip()
            logger.info(f"Conte√∫do limpo para parse: {content}")
            
            # Parsear JSON da resposta
            try:
                extracted = json.loads(content)
                logger.info(f"Informa√ß√µes extra√≠das: {extracted}")
                return extracted
            except json.JSONDecodeError as e:
                logger.error(f"Erro ao parsear JSON: {e}")
                logger.error(f"Conte√∫do que falhou: '{content}'")
                return {}
            
        except Exception as e:
            logger.error(f"Erro ao extrair informa√ß√µes: {e}")
            return {}
    
    def _execute_availability_check(self, extracted_data: Dict[str, Any], context: Dict[str, Any]) -> str:
        """Executa verifica√ß√£o de disponibilidade com suporte a busca por profissional OU procedimento"""
        try:
            # Obter regras expandidas da API
            api_rules = api_rules_engine.get_availability_check_rules_expanded(self.empresa_config)
            if not api_rules:
                return "Erro: Regras de disponibilidade n√£o configuradas"
            
            # Validar requisi√ß√£o
            validation = api_rules_engine.validate_availability_request(extracted_data, self.empresa_config)
            if not validation.get('valid'):
                # N√ÉO retornar erro direto - usar prompt principal do admin
                logger.info(f"Valida√ß√£o falhou: {validation.get('error')} - usando prompt principal do admin")
                return self._generate_response_with_company_prompt(
                    "verificar_disponibilidade",
                    {
                        'error': validation.get('error'),
                        'extracted_data': extracted_data,
                        'missing_fields': validation.get('missing_fields', []),
                        'context': context
                    },
                    context
                )
            
            search_type = validation.get('search_type')
            logger.info(f"Executando fluxo verificar_disponibilidade com tipo: {search_type}")
            
            # Executar fluxo expandido √∫nico
            return self._execute_expanded_availability_check(extracted_data, context, api_rules)
                
        except Exception as e:
            logger.error(f"Erro ao executar verifica√ß√£o de disponibilidade: {e}")
            # N√ÉO retornar erro direto - usar prompt principal do admin
            return self._generate_response_with_company_prompt(
                "verificar_disponibilidade",
                {
                    'error': f"Erro ao verificar disponibilidade: {str(e)}",
                    'context': context
                },
                context
            )
    

    


    def _execute_expanded_availability_check(self, data: Dict[str, Any], context: Dict[str, Any], api_rules: Dict[str, Any]) -> str:
        """Executa verifica√ß√£o de disponibilidade com fluxo expandido completo"""
        try:
            logger.info("Executando fluxo expandido de verifica√ß√£o de disponibilidade")
            
            # Obter passos configurados
            fluxo_config = api_rules.get('fluxos_por_intencao', {}).get('verificar_disponibilidade', {})
            passos = fluxo_config.get('passos', [])
            
            logger.info(f"Passos configurados: {passos}")
            
            # PASSO 1: Extrair dados (j√° feito)
            logger.info("PASSO 1: Dados extra√≠dos ‚úì")
            
            # PASSO 2: Determinar tipo de busca
            logger.info("PASSO 2: Determinando tipo de busca...")
            search_type = api_rules_engine.determine_search_type(data)
            logger.info(f"Tipo de busca: {search_type}")
            
            # PASSO 3: Buscar entidade (profissional ou servi√ßo)
            logger.info("PASSO 3: Buscando entidade...")
            entidade = None
            
            if search_type == 'por_profissional':
                # Buscar profissional
                profissionais = self._get_professionals_list()
                if not profissionais:
                    return self._generate_response_with_company_prompt(
                        "verificar_disponibilidade",
                        {'error': "N√£o consegui buscar a lista de profissionais", 'context': context},
                        context
                    )
                
                profissional = self._find_professional_match(data.get('profissional'), profissionais, fluxo_config.get('estrategias_match', []))
                if not profissional:
                    return self._generate_response_with_company_prompt(
                        "verificar_disponibilidade",
                        {'error': f"Profissional '{data.get('profissional')}' n√£o encontrado", 'context': context},
                        context
                    )
                
                entidade = {'tipo': 'profissional', 'dados': profissional}
                logger.info(f"Profissional encontrado: {profissional['nome']}")
                
                # IMPORTANTE: Para busca por profissional, precisamos identificar o servi√ßo tamb√©m
                if data.get('procedimento'):
                    # Usu√°rio mencionou o procedimento, fazer match
                    servicos = self._get_services_list()
                    if servicos:
                        servico = self._find_service_match(data.get('procedimento'), servicos, fluxo_config.get('estrategias_match', []))
                        if servico:
                            entidade['servico'] = servico
                            logger.info(f"Servi√ßo identificado para profissional: {servico['nome']}")
                        else:
                            logger.warning(f"Procedimento '{data.get('procedimento')}' n√£o encontrado, usando servi√ßo padr√£o")
                    else:
                        logger.warning("N√£o consegui buscar lista de servi√ßos para identificar procedimento")
                
            elif search_type == 'por_procedimento':
                # Buscar servi√ßo
                servicos = self._get_services_list()
                if not servicos:
                    return self._generate_response_with_company_prompt(
                        "verificar_disponibilidade",
                        {'error': "N√£o consegui buscar a lista de servi√ßos", 'context': context},
                        context
                    )
                
                servico = self._find_service_match(data.get('procedimento'), servicos, fluxo_config.get('estrategias_match', []))
                if not servico:
                    return self._generate_response_with_company_prompt(
                        "verificar_disponibilidade",
                        {'error': f"Servi√ßo '{data.get('procedimento')}' n√£o encontrado", 'context': context},
                        context
                    )
                
                entidade = {'tipo': 'servico', 'dados': servico}
                logger.info(f"Servi√ßo encontrado: {servico['nome']}")
                
            else:
                return self._generate_response_with_company_prompt(
                    "verificar_disponibilidade",
                    {'error': "Tipo de busca n√£o suportado", 'context': context},
                    context
                )
    
            # PASSO 4: Match inteligente (j√° feito)
            logger.info("PASSO 4: Match inteligente realizado ‚úì")
            
            # PASSO 5: Verificar prefer√™ncia de profissional - ABORDAGEM H√çBRIDA
            logger.info("PASSO 5: Verificando prefer√™ncia de profissional (ABORDAGEM H√çBRIDA)...")
            
            # ‚úÖ DETECTAR automaticamente se o usu√°rio j√° indicou prefer√™ncia
            if data.get('profissional') and data.get('profissional') != 'indiferente':
                logger.info(f"‚úÖ Usu√°rio j√° indicou prefer√™ncia: {data.get('profissional')}")
                # Continuar com busca espec√≠fica para este profissional
            else:
                # ‚úÖ IMPLEMENTAR ABORDAGEM H√çBRIDA: Buscar para TODOS os profissionais
                logger.info("üéØ ABORDAGEM H√çBRIDA: Usu√°rio sem prefer√™ncia espec√≠fica, buscando para TODOS os profissionais")
                
                if entidade['tipo'] == 'servico':
                    # Buscar disponibilidade de todos os profissionais para este servi√ßo
                    return self._check_availability_for_all_professionals(entidade['dados'], data.get('data'), context)
                else:
                    # Se for por profissional mas sem servi√ßo, perguntar procedimento
                    return self._generate_response_with_company_prompt(
                        "perguntar_procedimento",
                        {
                            'profissional': entidade['dados']['nome'],
                            'data': data.get('data'),
                            'context': context
                        },
                        context
                    )
            
            # PASSO 6: Buscar disponibilidade por servi√ßo
            logger.info("PASSO 6: Buscando disponibilidade por servi√ßo...")
            
            # IMPORTANTE: Sempre precisamos do servi√ßo para buscar disponibilidade
            servico_id = None
            profissional_id = None
            
            if entidade['tipo'] == 'servico':
                servico_id = entidade['dados']['id']
                profissional_id = data.get('profissional_id') if data.get('profissional_id') else None
            else:  # por_profissional
                if 'servico' in entidade:
                    servico_id = entidade['servico']['id']
                    profissional_id = entidade['dados']['id']
                else:
                    # Se n√£o temos servi√ßo, perguntar ao usu√°rio
                    return self._generate_response_with_company_prompt(
                        "perguntar_procedimento",
                        {
                            'profissional': entidade['dados']['nome'],
                            'data': data.get('data'),
                            'context': context
                        },
                        context
                    )
            
            # IMPORTANTE: Sempre usar o novo m√©todo _get_service_availability
            logger.info(f"Chamando _get_service_availability com servico_id={servico_id}, data={data.get('data')}, profissional_id={profissional_id}")
            disponibilidade = self._get_service_availability(servico_id, data.get('data'), profissional_id)
            
            if not disponibilidade:
                return self._generate_response_with_company_prompt(
                    "verificar_disponibilidade",
                    {
                        'error': f"N√£o h√° hor√°rios dispon√≠veis para {entidade['dados']['nome']} em {data.get('data')}",
                        'context': context
                    },
                    context
                )
            
            # PASSO 7: Validar slots por dura√ß√£o (SEMPRE executar!)
            logger.info("PASSO 7: Validando slots por dura√ß√£o...")
            
            # Obter dura√ß√£o do procedimento
            procedure_duration = api_rules_engine.get_procedure_duration(
                entidade.get('servico', entidade['dados'])['nome'], 
                context.get('empresa_config', {}),
                entidade.get('servico', entidade['dados'])  # Passar informa√ß√µes completas do servi√ßo
            )
            logger.info(f"Dura√ß√£o do procedimento '{entidade.get('servico', entidade['dados'])['nome']}': {procedure_duration} min")
            
            # Filtrar slots baseado na dura√ß√£o
            available_slots = disponibilidade.get('horariosVagos', [])
            if available_slots:
                # Converter hor√°rios para formato de slots
                slots_data = [{'horario': slot, 'disponivel': True} for slot in available_slots]
                
                # Aplicar valida√ß√£o de slots consecutivos
                valid_slots = api_rules_engine.filter_available_slots_by_duration(
                    slots_data, 
                    procedure_duration, 
                    context.get('empresa_config', {})
                )
                
                if valid_slots:
                    logger.info(f"Slots v√°lidos encontrados: {len(valid_slots)}")
                    # Converter de volta para hor√°rios
                    valid_horarios = [slot['horario_inicio'] for slot in valid_slots]
                    disponibilidade['horariosVagos'] = valid_horarios
                else:
                    logger.warning(f"Nenhum slot v√°lido encontrado para procedimento de {procedure_duration} min")
                    return self._generate_response_with_company_prompt(
                        "verificar_disponibilidade",
                        {
                            'error': f"N√£o h√° hor√°rios com slots consecutivos suficientes para '{entidade.get('servico', entidade['dados'])['nome']}' ({procedure_duration} min) em {data.get('data')}",
                            'context': context
                        },
                        context
                    )
            
            # PASSO 8: Retornar slots
            logger.info("PASSO 8: Formatando resposta com prompt da empresa...")
            return self._generate_response_with_company_prompt(
                "verificar_disponibilidade",
                {
                    'professional': entidade['dados']['nome'],
                    'date': data.get('data'),
                    'horarios': disponibilidade.get('horariosVagos', []),
                    'intervalos': disponibilidade.get('intervalosVagos', [])
                },
                context
            )
            
        except Exception as e:
            logger.error(f"Erro ao executar fluxo expandido: {e}")
            return self._generate_response_with_company_prompt(
                "verificar_disponibilidade",
                {
                    'error': f"Erro ao verificar disponibilidade: {str(e)}",
                    'context': context
                },
                context
            )
    
    def _execute_reservation_creation(self, data: Dict[str, Any], context: Dict[str, Any]) -> str:
        """Executa cria√ß√£o de reserva"""
        try:
            # Verificar campos obrigat√≥rios
            required_fields = ['profissional', 'data', 'horario', 'cliente']
            missing_fields = [field for field in required_fields if not data.get(field)]
            
            if missing_fields:
                return f"Para agendar, preciso das seguintes informa√ß√µes: {', '.join(missing_fields)}"
            
            # Aqui implementar√≠amos a cria√ß√£o real da reserva
            # Usar prompt da empresa para formatar resposta
            return self._generate_response_with_company_prompt(
                "agendar_consulta",
                data,
                context
            )
            
        except Exception as e:
            logger.error(f"Erro ao criar reserva: {e}")
            return "Desculpe, n√£o consegui criar a reserva no momento."
    
    def _execute_reservation_cancellation(self, data: Dict[str, Any], context: Dict[str, Any]) -> str:
        """Executa cancelamento de reserva"""
        try:
            if not data.get('data'):
                return "Preciso saber a data da consulta para cancelar."
            
            # Usar prompt da empresa para formatar resposta
            return self._generate_response_with_company_prompt(
                "cancelar_consulta",
                data,
                context
            )
            
        except Exception as e:
            logger.error(f"Erro ao cancelar reserva: {e}")
            return "Desculpe, n√£o consegui cancelar a reserva no momento."
    
    def _execute_reservation_reschedule(self, data: Dict[str, Any], context: Dict[str, Any]) -> str:
        """Executa reagendamento de reserva"""
        try:
            if not data.get('data_atual') or not data.get('nova_data'):
                return "Desculpe, preciso saber a data atual e a nova data para reagendar."
            
            # Usar prompt da empresa para formatar resposta
            return self._generate_response_with_company_prompt(
                "reagendar_consulta",
                data,
                context
            )
            
        except Exception as e:
            logger.error(f"Erro ao reagendar reserva: {e}")
            return "Desculpe, n√£o consegui reagendar a reserva no momento."
    
    def _call_trinks_api(self, endpoint: str, params: Dict[str, Any]) -> Dict[str, Any]:
        """Chama API Trinks real"""
        
        try:
            # Configura√ß√£o da API
            base_url = self.empresa_config.get('trinks_base_url')
            api_key = self.empresa_config.get('trinks_api_key')
            estabelecimento_id = self.empresa_config.get('trinks_estabelecimento_id')
            
            if not all([base_url, api_key, estabelecimento_id]):
                logger.error("Configura√ß√£o Trinks incompleta")
                return {"error": "Configura√ß√£o Trinks incompleta"}
            
            # Headers
            headers = {
                'X-API-KEY': api_key,
                'estabelecimentoId': estabelecimento_id,
                'Content-Type': 'application/json'
            }
            
            # Fazer requisi√ß√£o
            import requests
            response = requests.get(
                f"{base_url}{endpoint}",
                params=params,
                headers=headers,
                timeout=10
            )
            
            if response.status_code == 200:
                return response.json()
            else:
                logger.error(f"Erro na API Trinks: {response.status_code}")
                return {"error": f"HTTP {response.status_code}"}
                
        except Exception as e:
            logger.error(f"Erro ao chamar API Trinks: {e}")
            return {"error": str(e)}
    
    def _find_professional_match(self, nome_procurado: str, profissionais: List[Dict], estrategias: List[str]) -> Dict[str, Any]:
        """Usa LLM para fazer match inteligente entre nome procurado e lista de profissionais"""
        try:
            logger.info(f"LLM fazendo match inteligente para '{nome_procurado}' entre {len(profissionais)} profissionais")
            
            # Preparar prompt para o LLM
            system_prompt = f"""Voc√™ √© um assistente especializado em identificar profissionais de sa√∫de.

TAREFA: Identificar qual profissional da lista corresponde ao nome mencionado pelo usu√°rio.

NOME PROCURADO: "{nome_procurado}"

LISTA DE PROFISSIONAIS:
{json.dumps(profissionais, indent=2, ensure_ascii=False)}

INSTRU√á√ïES:
1. Analise o nome procurado e compare com a lista de profissionais
2. Considere varia√ß√µes de nomes, apelidos e t√≠tulos
3. Retorne o profissional com maior confian√ßa de match
4. Se houver ambiguidade, escolha o mais prov√°vel

FORMATO DE RESPOSTA (JSON):
{{
    "id": "ID do profissional",
    "nome": "Nome completo do profissional",
    "confianca": "ALTA|MEDIA|BAIXA",
    "razao": "Explica√ß√£o do match"
}}

RESPONDA APENAS em JSON v√°lido."""
            
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=f"Identifique o profissional '{nome_procurado}' na lista fornecida.")
            ]
            
            response = self.llm.invoke(messages)
            logger.info(f"Resposta do LLM para match: {response.content}")
            
            # Limpar e parsear resposta
            content = response.content.strip()
            if content.startswith('```json'):
                content = content[7:-3]  # Remove ```json e ```
            elif content.startswith('```'):
                content = content[3:-3]  # Remove ``` gen√©rico
            
            content = content.strip()
            logger.info(f"Conte√∫do limpo para parse: {content}")
            
            try:
                match_result = json.loads(content)
                
                # Buscar o profissional completo na lista original
                profissional_id = match_result.get('id')
                for prof in profissionais:
                    if str(prof.get('id')) == str(profissional_id):
                        logger.info(f"LLM encontrou profissional: {prof['nome']} (confian√ßa: {match_result.get('confianca', 'N/A')})")
                        logger.info(f"Raz√£o do match: {match_result.get('razao', 'N/A')}")
                        return prof
                
                logger.error(f"ID retornado pelo LLM n√£o encontrado na lista: {profissional_id}")
                return None
                
            except json.JSONDecodeError as e:
                logger.error(f"Erro ao parsear resposta do LLM: {e}")
                logger.error(f"Resposta recebida: {response.content}")
                return None
            
        except Exception as e:
            logger.error(f"Erro no match inteligente com LLM: {e}")
            return None
    
    # NOVOS M√âTODOS PARA FLUXO DE PROCEDIMENTO
    
    def _get_professionals_list(self) -> List[Dict[str, Any]]:
        """Busca lista de profissionais via API Trinks"""
        try:
            result = self._call_trinks_api("/profissionais", {})
            if result and not result.get('error'):
                return result.get('data', [])
            return []
        except Exception as e:
            logger.error(f"Erro ao buscar profissionais: {e}")
            return []
    
    def _get_services_list(self) -> List[Dict[str, Any]]:
        """Busca lista de servi√ßos via API Trinks com filtro de visibilidade"""
        try:
            logger.info("üîç Buscando TODOS os servi√ßos da API Trinks (pageSize=300 + filtro cliente)...")
            
            # Par√¢metros simples: uma chamada com pageSize grande
            params = {
                'page': 1,
                'pageSize': 300,  # Buscar 300 servi√ßos de uma vez
                'somenteVisiveisCliente': True  # Apenas servi√ßos vis√≠veis para cliente
            }
            
            result = self._call_trinks_api("/servicos", params)
            
            if result and not result.get('error'):
                servicos = result.get('data', [])
                logger.info(f"‚úÖ API Trinks retornou {len(servicos)} servi√ßos")
                
                # Log de TODOS os servi√ßos para debug completo
                if servicos:
                    logger.info(f"üìã TODOS os {len(servicos)} servi√ßos retornados pela API:")
                    for i, servico in enumerate(servicos):
                        nome = servico.get('nome', 'N/A')
                        categoria = servico.get('categoria', 'N/A')
                        duracao = servico.get('duracaoEmMinutos', 'N/A')
                        visivel = servico.get('somenteVisiveisCliente', 'N/A')
                        logger.info(f"   {i+1:3d}. {nome} | Categoria: {categoria} | Dura√ß√£o: {duracao}min | Vis√≠vel: {visivel}")
                    
                    # Log de todas as categorias dispon√≠veis
                    categorias = set(serv.get('categoria', 'Sem categoria') for serv in servicos)
                    logger.info(f"üè∑Ô∏è  Categorias dispon√≠veis: {sorted(list(categorias))}")
                    
                    # Procurar por servi√ßos que contenham "limpeza" ou "pele"
                    logger.info("üîç Procurando por servi√ßos com 'limpeza' ou 'pele'...")
                    servicos_limpeza = []
                    for serv in servicos:
                        nome = serv.get('nome', '').lower()
                        if 'limpeza' in nome or 'pele' in nome:
                            servicos_limpeza.append(serv)
                    
                    if servicos_limpeza:
                        logger.info(f"‚úÖ Encontrados {len(servicos_limpeza)} servi√ßos relacionados:")
                        for serv in servicos_limpeza:
                            logger.info(f"   - {serv.get('nome')} (ID: {serv.get('id')})")
                    else:
                        logger.info("‚ùå Nenhum servi√ßo encontrado com 'limpeza' ou 'pele'")
                    
                    # Mostrar TODOS os servi√ßos da categoria "Est√©tica Facial"
                    logger.info("üîç TODOS os servi√ßos da categoria 'Est√©tica Facial':")
                    servicos_facial = [s for s in servicos if s.get('categoria') == 'Est√©tica Facial']
                    if servicos_facial:
                        for serv in servicos_facial:
                            logger.info(f"   - {serv.get('nome')} (ID: {serv.get('id')}) | Dura√ß√£o: {serv.get('duracaoEmMinutos', 'N/A')}min")
                    else:
                        logger.info("   Nenhum servi√ßo encontrado na categoria 'Est√©tica Facial'")
                
                return servicos
            else:
                logger.error(f"‚ùå Erro na API Trinks: {result}")
            return []
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao buscar servi√ßos: {e}")
            return []
    
    def _get_professional_availability(self, profissional_id: str, data: str) -> Dict[str, Any]:
        """Busca disponibilidade de um profissional em uma data espec√≠fica"""
        try:
            logger.info(f"Buscando disponibilidade para profissional ID {profissional_id} na data {data}")
            
            result = self._call_trinks_api(
                f"/agendamentos/profissionais/{data}",
                {'profissionalId': profissional_id}
            )
            
            if result and not result.get('error'):
                # Retornar dados do profissional espec√≠fico
                for prof in result.get('data', []):
                    if str(prof.get('id')) == str(profissional_id):
                        return prof
            return {}
            
        except Exception as e:
            logger.error(f"Erro ao buscar disponibilidade: {e}")
            return {}
    
    def _get_service_availability(self, servico_id: str, data: str, profissional_id: str = None) -> Dict[str, Any]:
        """Busca disponibilidade de um servi√ßo em uma data espec√≠fica, com filtro opcional de profissional"""
        try:
            logger.info(f"Buscando disponibilidade para servi√ßo ID {servico_id} na data {data}" + (f" com filtro de profissional {profissional_id}" if profissional_id else ""))
            
            # Construir endpoint CORRETO conforme documenta√ß√£o Trinks
            endpoint = f"/agendamentos/profissionais/{data}"
            params = {}
            
            # Adicionar par√¢metros conforme documenta√ß√£o
            if servico_id:
                params['servicold'] = servico_id  # ID do servi√ßo
            
            if profissional_id:
                params['profissionalld'] = profissional_id  # ID do profissional
            
            logger.info(f"DEBUG: Endpoint={endpoint}, Params={params}")
            result = self._call_trinks_api(endpoint, params)
            
            if result and not result.get('error'):
                # Processar dados da API para extrair disponibilidade
                logger.info(f"DEBUG: Dados brutos da API: {result}")
                
                # Extrair dados do profissional espec√≠fico se filtrado
                if profissional_id:
                    for prof in result.get('data', []):
                        if str(prof.get('id')) == str(profissional_id):
                            logger.info(f"DEBUG: Profissional encontrado: {prof}")
                            return {
                                'horariosVagos': prof.get('horariosVagos', []),
                                'intervalosVagos': prof.get('intervalosVagos', []),
                                'profissional': prof
                            }
                
                # Se n√£o filtrado por profissional, retornar todos
                logger.info(f"DEBUG: Retornando dados para todos os profissionais")
                return {
                    'horariosVagos': result.get('data', []),
                    'intervalosVagos': [],
                    'profissionais': result.get('data', [])
                }
            
            logger.warning(f"DEBUG: API retornou erro ou dados vazios: {result}")
            return {}
            
        except Exception as e:
            logger.error(f"Erro ao buscar disponibilidade do servi√ßo: {e}")
            return {}
    
    def _find_service_match(self, nome_procurado: str, servicos: List[Dict], estrategias: List[str]) -> Dict[str, Any]:
        """Usa LLM para fazer match inteligente entre nome procurado e lista de servi√ßos"""
        try:
            logger.info(f"ü§ñ LLM fazendo match inteligente de servi√ßo para '{nome_procurado}' entre {len(servicos)} servi√ßos")
            logger.info(f"üìä Servi√ßos que ser√£o analisados pelo LLM:")
            for i, serv in enumerate(servicos[:5]):  # Mostrar apenas os primeiros 5 para n√£o poluir o log
                logger.info(f"   {i+1}. {serv.get('nome', 'N/A')} | Categoria: {serv.get('categoria', 'N/A')}")
            if len(servicos) > 5:
                logger.info(f"   ... e mais {len(servicos) - 5} servi√ßos")
            
            # Preparar prompt para o LLM
            system_prompt = f"""Voc√™ √© um assistente especializado em identificar servi√ßos de sa√∫de.

TAREFA: Identificar qual servi√ßo da lista corresponde ao nome mencionado pelo usu√°rio.

NOME PROCURADO: "{nome_procurado}"

LISTA DE SERVI√áOS:
{json.dumps(servicos, indent=2, ensure_ascii=False)}

ESTRAT√âGIA DE MATCH:
1. **Busca por Palavras-Chave**: Procure por servi√ßos que contenham as palavras principais do nome procurado
2. **Correspond√™ncia Parcial**: N√£o exija match exato - procure por correspond√™ncias parciais
3. **Sin√¥nimos**: Considere varia√ß√µes e sin√¥nimos
4. **Categorias**: Procure por servi√ßos da mesma categoria

EXEMPLOS:
- "limpeza de pele" ‚Üí Procure por servi√ßos que contenham "limpeza" E "pele"
- "massagem relaxante" ‚Üí Procure por servi√ßos que contenham "massagem" OU "relaxante"
- "aplica√ß√£o de enzimas" ‚Üí Procure por servi√ßos que contenham "enzimas" OU "aplica√ß√£o"

INSTRU√á√ïES:
1. Analise o nome procurado e identifique palavras-chave principais
2. Procure na lista por servi√ßos que contenham essas palavras-chave
3. Considere correspond√™ncias parciais - n√£o exija match exato
4. Se encontrar m√∫ltiplos matches, escolha o mais relevante
5. SEMPRE tente encontrar um match - nunca retorne null

FORMATO DE RESPOSTA (JSON):
{{
    "id": "ID do servi√ßo",
    "nome": "Nome completo do servi√ßo",
    "confianca": "ALTA|MEDIA|BAIXA",
    "razao": "Explica√ß√£o do match e palavras-chave encontradas"
}}

IMPORTANTE: 
- SEMPRE tente encontrar um match, mesmo que n√£o seja perfeito
- Use correspond√™ncia parcial - n√£o exija match exato
- Se n√£o encontrar match exato, escolha o mais pr√≥ximo
- NUNCA retorne id ou nome como null

RESPONDA APENAS em JSON v√°lido."""
            
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=f"Identifique o servi√ßo '{nome_procurado}' na lista fornecida.")
            ]
            
            response = self.llm.invoke(messages)
            logger.info(f"Resposta do LLM para match de servi√ßo: {response.content}")
            
            # Limpar e parsear resposta
            content = response.content.strip()
            if content.startswith('```json'):
                content = content[7:-3]  # Remove ```json e ```
            elif content.startswith('```'):
                content = content[3:-3]  # Remove ``` gen√©rico
            
            content = content.strip()
            logger.info(f"Conte√∫do limpo para parse: {content}")
            
            match_result = json.loads(content)
            
            # Buscar o servi√ßo completo na lista original
            servico_id = match_result.get('id')
            for serv in servicos:
                if str(serv.get('id')) == str(servico_id):
                    logger.info(f"LLM encontrou servi√ßo: {serv['nome']} (confian√ßa: {match_result.get('confianca', 'N/A')})")
                    logger.info(f"Raz√£o do match: {match_result.get('razao', 'N/A')}")
                    return serv
            
            logger.error(f"ID retornado pelo LLM n√£o encontrado na lista: {servico_id}")
            return None
            
        except json.JSONDecodeError as e:
            logger.error(f"Erro ao parsear resposta do LLM: {e}")
            logger.error(f"Resposta recebida: {response.content}")
            return None
        
        except Exception as e:
            logger.error(f"Erro no match inteligente de servi√ßo: {e}")
            return None
    
    def _get_professionals_by_service(self, servico_id: str) -> List[Dict[str, Any]]:
        """Busca profissionais que fazem um servi√ßo espec√≠fico"""
        try:
            # Por enquanto, retornar todos os profissionais (implementar filtro depois)
            # TODO: Implementar filtro por servi√ßo quando a API Trinks suportar
            return self._get_professionals_list()
        except Exception as e:
            logger.error(f"Erro ao buscar profissionais por servi√ßo: {e}")
            return []
    
    def _generate_professional_preference_question(self, servico: Dict[str, Any], profissionais: List[Dict[str, Any]], data: str, context: Dict[str, Any]) -> str:
        """Gera pergunta para o usu√°rio escolher profissional preferido"""
        try:
            # Usar prompt da empresa para formatar a pergunta
            return self._generate_response_with_company_prompt(
                "perguntar_preferencia_profissional",
                {
                    'servico': servico['nome'],
                    'data': data,
                    'profissionais_disponiveis': len(profissionais),
                    'nomes_profissionais': [p.get('nome', 'N/A') for p in profissionais[:3]]  # Mostrar primeiros 3
                },
                context
            )
            
        except Exception as e:
            logger.error(f"Erro ao gerar pergunta de prefer√™ncia: {e}")
            # Fallback para resposta padr√£o
            return f"Perfeito! Encontrei o servi√ßo '{servico['nome']}' e {len(profissionais)} profissionais dispon√≠veis para {data}. Tem algum profissional espec√≠fico em mente, ou posso mostrar a disponibilidade de todos?" 
    
    def _generate_response_with_company_prompt(self, action_type: str, data: Dict[str, Any], context: Dict[str, Any] = None) -> str:
        """Gera resposta personalizada usando o prompt da empresa para qualquer tipo de a√ß√£o"""
        
        # Obter prompt da empresa
        company_prompt = self.empresa_config.get('prompt', '')
        company_name = self.empresa_config.get('nome', 'Empresa')
        
        # Preparar dados para o LLM
        system_prompt = f"""Voc√™ √© um assistente virtual da {company_name}.

PROMPT DA EMPRESA:
{company_prompt if company_prompt else 'Responda de forma profissional e amig√°vel.'}

INSTRU√á√ïES:
- Use o tom de voz e estilo definidos no prompt da empresa
- Siga as regras sobre o que falar e o que n√£o falar
- Mantenha a identidade da empresa
- Seja consistente com o estilo de comunica√ß√£o

TIPO DE A√á√ÉO: {action_type}

DADOS DISPON√çVEIS:
{json.dumps(data, indent=2, ensure_ascii=False)}

RESPONDA de acordo com o prompt da empresa, formatando a resposta de forma clara e profissional."""
        
        try:
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=f"Formate uma resposta para {action_type} usando os dados fornecidos e seguindo o prompt da empresa.")
            ]
            
            response = self.llm.invoke(messages)
            logger.info(f"Resposta gerada com prompt da empresa para {action_type}")
            return response.content.strip()
            
        except Exception as e:
            logger.error(f"Erro ao gerar resposta com prompt da empresa: {e}")
            # Fallback para resposta padr√£o
            return self._generate_fallback_response(action_type, data)
    
    def _generate_fallback_response(self, action_type: str, data: Dict[str, Any]) -> str:
        """Gera resposta de fallback quando o prompt da empresa falha"""
        
        if action_type == "verificar_disponibilidade":
            professional = data.get('professional', 'Profissional')
            date = data.get('date', 'Data')
            horarios = data.get('horarios', [])
            intervalos = data.get('intervalos', [])
            
            if horarios or intervalos:
                response = f"‚úÖ Hor√°rios dispon√≠veis para {professional}:\n\n"
                
                if horarios:
                    response += "üïê Hor√°rios espec√≠ficos:\n"
                    for horario in horarios:
                        response += f"‚Ä¢ {horario}\n"
                    response += "\n"
                
                if intervalos:
                    response += "‚è∞ Intervalos dispon√≠veis:\n"
                    for intervalo in intervalos:
                        response += f"‚Ä¢ {intervalo.get('inicio', '')} - {intervalo.get('fim', '')}\n"
                
                response += f"\nüìÖ Data: {date}"
                return response
            else:
                return f"Infelizmente a {professional} n√£o tem hor√°rios dispon√≠veis para {date}."
        
        elif action_type == "perguntar_preferencia_profissional":
            servico = data.get('servico', 'servi√ßo')
            data_str = data.get('data', 'data')
            profissionais_count = data.get('profissionais_disponiveis', 0)
            return f"Perfeito! Encontrei o servi√ßo '{servico}' e {profissionais_count} profissionais dispon√≠veis para {data_str}. Tem algum profissional espec√≠fico em mente, ou posso mostrar a disponibilidade de todos?"
        
        elif action_type == "perguntar_procedimento":
            profissional = data.get('profissional', 'profissional')
            data_str = data.get('data', 'data')
            return f"Perfeito! Encontrei a {profissional} dispon√≠vel para {data_str}. Qual procedimento voc√™ gostaria de agendar?"
        
        elif action_type == "agendar_consulta":
            return f"Perfeito! Vou agendar sua consulta com {data.get('profissional', 'profissional')} para {data.get('data', 'data')} √†s {data.get('horario', 'hor√°rio')}."
        
        elif action_type == "cancelar_consulta":
            return f"Vou cancelar sua consulta de {data.get('data', 'data')}. Confirma o cancelamento?"
        
        elif action_type == "reagendar_consulta":
            return f"Vou reagendar sua consulta de {data.get('data_atual', 'data atual')} para {data.get('nova_data', 'nova data')}."
        
        else:
            return f"A√ß√£o '{action_type}' processada com sucesso." 
    
    def _get_conversation_state(self, waid: str) -> Dict[str, Any]:
        """Obt√©m o estado atual da conversa para um waid espec√≠fico"""
        if not hasattr(self, '_conversation_states'):
            self._conversation_states = {}
        
        if waid not in self._conversation_states:
            self._conversation_states[waid] = {
                'profissional': None,
                'procedimento': None,
                'data': None,
                'horario': None,
                'servico': None,
                'preferencia_profissional': None,
                'last_update': None
            }
        
        return self._conversation_states[waid]
    
    def _update_conversation_state(self, waid: str, new_data: Dict[str, Any]):
        """Atualiza o estado da conversa com novas informa√ß√µes extra√≠das"""
        state = self._get_conversation_state(waid)
        
        # ‚úÖ PRESERVAR CONTEXTO: S√≥ atualizar campos que foram realmente mencionados
        for key, value in new_data.items():
            if value is not None and value != "" and value != "null":
                # ‚úÖ Atualiza apenas se o valor for v√°lido
                state[key] = value
                logger.info(f"Campo '{key}' atualizado para: {value}")
            else:
                # ‚úÖ Preserva o valor anterior se o campo n√£o foi mencionado
                logger.info(f"Campo '{key}' preservado com valor anterior: {state.get(key, 'N/A')}")
        
        state['last_update'] = datetime.now()
        logger.info(f"Estado da conversa atualizado para waid {waid}: {state}")
    
    def _merge_extracted_with_state(self, waid: str, extracted_data: Dict[str, Any]) -> Dict[str, Any]:
        """Combina dados extra√≠dos com o estado persistente da conversa de forma inteligente"""
        state = self._get_conversation_state(waid)
        merged_data = state.copy()
        
        # ‚úÖ MESCLAGEM INTELIGENTE: Preservar contexto anterior, atualizar apenas o que mudou
        for key, value in extracted_data.items():
            if value is not None and value != "" and value != "null":
                # ‚úÖ Campo foi mencionado na nova mensagem - atualizar
                old_value = merged_data.get(key, 'N/A')
                merged_data[key] = value
                logger.info(f"‚úÖ Campo '{key}' atualizado: '{old_value}' ‚Üí '{value}'")
            else:
                # ‚úÖ Campo n√£o foi mencionado - preservar valor anterior
                preserved_value = merged_data.get(key, 'N/A')
                logger.info(f"üîÑ Campo '{key}' preservado: '{preserved_value}'")
        
        # Remover campos internos do estado
        merged_data.pop('last_update', None)
        
        logger.info(f"üéØ Dados mesclados para waid {waid}: {merged_data}")
        
        # ‚úÖ VALIDA√á√ÉO FINAL: Garantir que campos cr√≠ticos n√£o sejam perdidos
        critical_fields = ['procedimento', 'data', 'profissional']
        for field in critical_fields:
            if field in merged_data and merged_data[field] and field not in extracted_data:
                logger.info(f"üõ°Ô∏è Campo cr√≠tico '{field}' preservado: '{merged_data[field]}'")
            elif field not in merged_data or not merged_data[field]:
                logger.warning(f"‚ö†Ô∏è Campo cr√≠tico '{field}' n√£o encontrado no estado final")
        
        return merged_data
    
    def _detectar_preferencia_profissional(self, mensagem: str) -> Dict[str, Any]:
        """Detecta se o usu√°rio tem prefer√™ncia por profissional ou √© indiferente"""
        try:
            prompt = f"""
            Analise a seguinte mensagem do usu√°rio e determine se ele est√° indicando que N√ÉO tem prefer√™ncia por profissional espec√≠fico.

            Mensagem: "{mensagem}"

            Responda apenas com um JSON v√°lido:
            {{
                "tem_preferencia": true/false,
                "profissional_especifico": "nome_do_profissional" ou null,
                "razao": "explicacao_curta"
            }}

            Exemplos de "SEM prefer√™ncia":
            - "tanto faz", "qualquer um", "n√£o tenho prefer√™ncia"
            - "pode ser qualquer um", "indiferente", "n√£o importa"
            - "o que tiver dispon√≠vel", "o melhor hor√°rio"

            Exemplos de "COM prefer√™ncia":
            - "com a Dr. Maria", "quero o Jo√£o", "prefiro a Ana"
            - "gostaria da Dra. Silva", "pode ser o Dr. Carlos"
            """
            
            messages = [
                SystemMessage(content=prompt),
                HumanMessage(content=mensagem)
            ]
            
            response = self.llm.invoke(messages)
            content = response.content.strip()
            
            # Limpar resposta do LLM
            if content.startswith('```json'):
                content = content[7:-3]
            elif content.startswith('```'):
                content = content[3:-3]
            
            content = content.strip()
            logger.info(f"Resposta do LLM para prefer√™ncia: {content}")
            
            # Parsear JSON
            try:
                result = json.loads(content)
                logger.info(f"Prefer√™ncia detectada: {result}")
                return result
            except json.JSONDecodeError as e:
                logger.error(f"Erro ao parsear JSON da prefer√™ncia: {e}")
                return {"tem_preferencia": True, "profissional_especifico": None, "razao": "Erro no parse"}
                
        except Exception as e:
            logger.error(f"Erro ao detectar prefer√™ncia de profissional: {e}")
            return {"tem_preferencia": True, "profissional_especifico": None, "razao": "Erro na detec√ß√£o"} 

    def _check_availability_for_all_professionals(self, servico: Dict[str, Any], data: str, context: Dict[str, Any]) -> str:
        """Verifica disponibilidade de TODOS os profissionais para um servi√ßo e data - ABORDAGEM H√çBRIDA"""
        try:
            logger.info(f"üîç ABORDAGEM H√çBRIDA: Verificando disponibilidade de TODOS os profissionais para {servico['nome']} em {data}")
            
            # Buscar disponibilidade de todos os profissionais
            disponibilidade_total = []
            profissionais_com_horarios = []
            
            # Buscar lista de profissionais que fazem o servi√ßo
            profissionais = self._get_professionals_list()
            logger.info(f"üìã Analisando {len(profissionais)} profissionais para o servi√ßo")
            
            for prof in profissionais:
                # Buscar disponibilidade espec√≠fica para este profissional + servi√ßo + data
                disponibilidade = self._get_service_availability(servico['id'], data, prof['id'])
                
                if disponibilidade and disponibilidade.get('horariosVagos'):
                    # Obter dura√ß√£o do procedimento para valida√ß√£o
                    procedure_duration = api_rules_engine.get_procedure_duration(
                        servico['nome'], 
                        context.get('empresa_config', {}),
                        servico
                    )
                    
                    # Validar slots por dura√ß√£o
                    available_slots = disponibilidade.get('horariosVagos', [])
                    if available_slots:
                        slots_data = [{'horario': slot, 'disponivel': True} for slot in available_slots]
                        valid_slots = api_rules_engine.filter_available_slots_by_duration(
                            slots_data, 
                            procedure_duration, 
                            context.get('empresa_config', {})
                        )
                        
                        if valid_slots:
                            valid_horarios = [slot['horario_inicio'] for slot in valid_slots]
                            profissionais_com_horarios.append({
                                'profissional': prof,
                                'horarios': valid_horarios,
                                'quantidade_horarios': len(valid_horarios),
                                'disponibilidade_bruta': disponibilidade
                            })
                            logger.info(f"‚úÖ {prof['nome']}: {len(valid_horarios)} hor√°rios v√°lidos")
                        else:
                            logger.info(f"‚ùå {prof['nome']}: hor√°rios n√£o atendem dura√ß√£o do procedimento")
                    else:
                        logger.info(f"‚ùå {prof['nome']}: sem hor√°rios dispon√≠veis")
                else:
                    logger.info(f"‚ùå {prof['nome']}: sem disponibilidade para este servi√ßo/data")
            
            if not profissionais_com_horarios:
                return self._generate_response_with_company_prompt(
                    "verificar_disponibilidade",
                    {
                        'error': f"N√£o h√° hor√°rios dispon√≠veis para {servico['nome']} em {data}",
                        'suggestion': "Gostaria de verificar outra data?",
                        'context': context
                    },
                    context
                )
            
            # ‚úÖ PRIORIZAR por quantidade de hor√°rios (mais hor√°rios primeiro)
            profissionais_com_horarios.sort(key=lambda x: x['quantidade_horarios'], reverse=True)
            
            logger.info(f"üéØ Profissionais ordenados por prioridade (mais hor√°rios primeiro):")
            for i, prof in enumerate(profissionais_com_horarios):
                logger.info(f"   {i+1}. {prof['profissional']['nome']}: {prof['quantidade_horarios']} hor√°rios")
            
            # Retornar disponibilidade priorizada de todos os profissionais
            return self._generate_response_with_company_prompt(
                "verificar_disponibilidade",
                {
                    'servico': servico,
                    'data': data,
                    'disponibilidade': profissionais_com_horarios,
                    'tipo': 'todos_profissionais_priorizados',
                    'context': context
                },
                context
            )
            
        except Exception as e:
            logger.error(f"Erro ao verificar disponibilidade de todos os profissionais: {e}")
            return self._generate_response_with_company_prompt(
                "verificar_disponibilidade",
                {
                    'error': f"Erro ao verificar disponibilidade: {str(e)}",
                    'context': context
                },
                context
            )
    
    def _check_availability_for_specific_professional(self, servico: Dict[str, Any], profissional_nome: str, data: str, context: Dict[str, Any]) -> str:
        """Verifica disponibilidade de um profissional espec√≠fico para um servi√ßo e data"""
        try:
            logger.info(f"Verificando disponibilidade de {profissional_nome} para {servico['nome']} em {data}")
            
            # Buscar lista de profissionais para fazer match
            profissionais = self._get_professionals_list()
            profissional = self._find_professional_match(profissional_nome, profissionais, [])
            
            if not profissional:
                return self._generate_response_with_company_prompt(
                    "verificar_disponibilidade",
                    {
                        'error': f"N√£o consegui identificar o profissional '{profissional_nome}'",
                        'suggestion': "Pode ser mais espec√≠fico?",
                        'context': context
                    },
                    context
                )
            
            # Verificar disponibilidade do profissional espec√≠fico
            disponibilidade = self._get_professional_availability(profissional['id'], data)
            
            if not disponibilidade or not disponibilidade.get('horarios_disponiveis'):
                return self._generate_response_with_company_prompt(
                    "verificar_disponibilidade",
                    {
                        'error': f"{profissional['nome']} n√£o tem hor√°rios dispon√≠veis para {servico['nome']} em {data}",
                        'suggestion': "Gostaria de verificar outra data ou outro profissional?",
                        'context': context
                    },
                    context
                )
            
            # Retornar disponibilidade do profissional espec√≠fico
            return self._generate_response_with_company_prompt(
                "verificar_disponibilidade",
                {
                    'servico': servico,
                    'profissional': profissional,
                    'data': data,
                    'disponibilidade': disponibilidade.get('horarios_disponiveis', []),
                    'tipo': 'profissional_especifico',
                    'context': context
                },
                context
            )
            
        except Exception as e:
            logger.error(f"Erro ao verificar disponibilidade de profissional espec√≠fico: {e}")
            return self._generate_response_with_company_prompt(
                "verificar_disponibilidade",
                {
                    'error': f"Erro ao verificar disponibilidade: {str(e)}",
                    'context': context
                },
                context
            )
    
    def _generate_generic_preference_question(self, servico: Dict[str, Any], data: str, context: Dict[str, Any]) -> str:
        """Gera pergunta gen√©rica sobre prefer√™ncia de profissional SEM sugerir nomes"""
        try:
            return self._generate_response_with_company_prompt(
                "verificar_disponibilidade",
                {
                    'servico': servico,
                    'data': data,
                    'pergunta': 'preferencia_generica',
                    'context': context
                },
                context
            )
        except Exception as e:
            logger.error(f"Erro ao gerar pergunta de prefer√™ncia gen√©rica: {e}")
            return "Gostaria de verificar a disponibilidade de todos os profissionais ou tem alguma prefer√™ncia espec√≠fica?" 